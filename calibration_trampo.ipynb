{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration tests\n",
    "### Pose2Sim calibration.py functions\n",
    "### Data test trampo (CRME)\n",
    "\n",
    "Auteurs : Léa Drolet-Roy\n",
    "\n",
    "Création : 2025-03-17\n",
    "\n",
    "Dernière modification :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import pyswarms as ps\n",
    "from pyswarms.utils.plotters import plot_cost_history\n",
    "\n",
    "from Calibration import calibration as cali\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKERBOARD = (9,4)\n",
    "image_size = (1080,1920)\n",
    "\n",
    "aruco_name = cv2.aruco.DICT_4X4_100\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(aruco_name)\n",
    "charuco_board = cv2.aruco.CharucoBoard(CHECKERBOARD, 112, 86, aruco_dict)\n",
    "\n",
    "cams = ['c1', 'c2', 'c3', 'c5', 'c6', 'c7', 'c8']\n",
    "time_threshold = 15\n",
    "\n",
    "path = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\video_test'\n",
    "calib_dir = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\video_test\\corners_found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Charuco Board creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "LENGTH_PX = 640\n",
    "MARGIN_PX = 20\n",
    "\n",
    "def create_and_save_new_board():\n",
    "    dictionary = cv2.aruco.getPredefinedDictionary(aruco_name)\n",
    "    board = cv2.aruco.CharucoBoard(CHECKERBOARD, 112, 86, dictionary)\n",
    "    size_ratio = CHECKERBOARD[1] / CHECKERBOARD[0]\n",
    "    img = cv2.aruco.CharucoBoard.generateImage(board, (LENGTH_PX, int(LENGTH_PX*size_ratio)), marginSize=MARGIN_PX)\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey(2000)\n",
    "\n",
    "create_and_save_new_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCorners(img=None, im_name=None):\n",
    "    if im_name is not None:\n",
    "        img = cv2.imread(im_name)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError('No image nor image path specified')\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=params)\n",
    "\n",
    "    if ids is not None: # and len(ids) >= 4:\n",
    "        _, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(corners, ids, gray, charuco_board)\n",
    "        if charuco_corners is not None and len(charuco_corners) > 0:\n",
    "            return corners, charuco_corners, charuco_ids\n",
    "        \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and save frames where CharucoBoard is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2654 frames, saved 836 valid Charuco frames.\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "output_dir = os.path.join(path, 'corners_found')\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure output folder exists\n",
    "\n",
    "intrinsics_extension = 'mp4'\n",
    "intrinsics_cam_listdirs_names = next(os.walk(os.path.join(path, 'intrinsics')))[1]\n",
    "\n",
    "detector_params = cv2.aruco.DetectorParameters()\n",
    "\n",
    "for i, cam in enumerate(intrinsics_cam_listdirs_names):\n",
    "    os.makedirs(os.path.join(output_dir, cam), exist_ok=True)\n",
    "    video_path = glob.glob(os.path.join(path, 'intrinsics', cam, f'*.{intrinsics_extension}'))\n",
    "    if len(video_path) == 0:\n",
    "        raise ValueError(f'The folder {os.path.join(path, 'intrinsics', cam)} does not contain any .{intrinsics_extension} video files.')\n",
    "\n",
    "    frame_count = 0\n",
    "    valid_frame_count = 0\n",
    "\n",
    "    for img_path in video_path:\n",
    "        cap = cv2.VideoCapture(img_path)\n",
    "        frame_count = 0\n",
    "        valid_frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            corners, charuco_corners, charuco_ids = findCorners(frame)\n",
    "\n",
    "            if charuco_corners is not None and charuco_ids is not None:\n",
    "                valid_frame_count += 1\n",
    "                frame_filename = os.path.join(output_dir, cam, f\"charuco_frame_{valid_frame_count:03d}.png\")\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processed {frame_count} frames, saved {valid_frame_count} valid Charuco frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_intrinsics(calib_dir, cams, image_size, camera_matrix=None, dist_coeffs=None):\n",
    "    intrinsics_extension = 'png'\n",
    "    ret, C, S, D, K = [], [], [], [], []\n",
    "\n",
    "    for cam in cams:\n",
    "        image_files = sorted(glob.glob(os.path.join(calib_dir, cam, \"*.png\")))  # Adjust extension if needed\n",
    "        if len(image_files) == 0:\n",
    "            raise ValueError(f'The folder {os.path.join(calib_dir, cam)} does not contain images with .{intrinsics_extension}')\n",
    "        \n",
    "        # Data storage\n",
    "        imgpoints = []  # Detected charuco corners\n",
    "        charuco_ids = []  # Corresponding IDs\n",
    "        image_size = None  # To store image resolution\n",
    "\n",
    "        # Process each image\n",
    "        for img_path in image_files:\n",
    "            img = cv2.imread(img_path)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            if image_size is None:\n",
    "                image_size = gray.shape[::-1]  # Get image size from first frame\n",
    "\n",
    "            # Detect Aruco markers\n",
    "            corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict)\n",
    "\n",
    "            if ids is not None:\n",
    "                # Refine detection by interpolating Charuco corners\n",
    "                _, charuco_corners, charuco_ids_found = cv2.aruco.interpolateCornersCharuco(\n",
    "                    markerCorners=corners, markerIds=ids, image=gray, board=charuco_board)\n",
    "\n",
    "                if charuco_corners is not None and len(charuco_corners) > 6:  # Ensure enough points\n",
    "                    imgpoints.append(charuco_corners)\n",
    "                    charuco_ids.append(charuco_ids_found)\n",
    "        \n",
    "        # Ensure we have enough valid frames\n",
    "        if len(imgpoints) < 10:\n",
    "            raise ValueError(f\"Not enough valid images for calibration of {cam}! Need at least 10.\")\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        imgpoints = [np.array(p, dtype=np.float32) for p in imgpoints]\n",
    "        charuco_ids = [np.array(p, dtype=np.int32) for p in charuco_ids]\n",
    "\n",
    "        # Run calibration\n",
    "        ret_cam, mtx, dist, _, _ = cv2.aruco.calibrateCameraCharuco(\n",
    "            charucoCorners=imgpoints,\n",
    "            charucoIds=charuco_ids,\n",
    "            board=charuco_board,\n",
    "            imageSize=image_size,\n",
    "            cameraMatrix=camera_matrix,  # Use initialized matrix\n",
    "            distCoeffs=dist_coeffs,\n",
    "            flags=cv2.CALIB_USE_INTRINSIC_GUESS+cv2.CALIB_USE_LU\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        h, w = map(np.float32, image_size)\n",
    "        ret.append(ret_cam)\n",
    "        C.append(cam)\n",
    "        S.append([w, h])\n",
    "        D.append(dist)\n",
    "        K.append(mtx)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\nCalibration completed for camera: {cam}\")\n",
    "        print(f'Error: {ret_cam:.4f}')\n",
    "        print(\"Camera Matrix:\\n\", mtx)\n",
    "        print(\"Distortion Coefficients:\\n\", dist)\n",
    "\n",
    "    return ret, C, S, D, K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try setting an initial camera matrix\n",
    "h, w = image_size\n",
    "focal_length = 2000  # Approximate focal length\n",
    "camera_matrix_init = np.array([\n",
    "    [focal_length, 0, w / 2],\n",
    "    [0, focal_length, h / 2],\n",
    "    [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "ret, C, S, D, K = calibrate_intrinsics(calib_dir, cams, image_size, camera_matrix_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array(K)\n",
    "np.savez('Intrinsics_K_trampo.npz', K)\n",
    "\n",
    "D = np.array(D)\n",
    "np.savez('Intrinsics_D_trampo.npz', D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsics: \n",
      "[[1249.0508    0.      936.0954]\n",
      " [   0.     1247.4435  536.2969]\n",
      " [   0.        0.        1.    ]] \n",
      "[[1251.7008    0.      961.0123]\n",
      " [   0.     1240.7726  545.1083]\n",
      " [   0.        0.        1.    ]] \n",
      "[[2158.3037    0.      968.1835]\n",
      " [   0.     2163.0135  538.9601]\n",
      " [   0.        0.        1.    ]] \n",
      "[[1450.8422    0.     1009.3212]\n",
      " [   0.     1413.1678  511.3463]\n",
      " [   0.        0.        1.    ]] \n",
      "[[2165.2584    0.      951.3176]\n",
      " [   0.     2169.1016  499.3   ]\n",
      " [   0.        0.        1.    ]] \n",
      "[[2165.3993    0.      932.488 ]\n",
      " [   0.     2137.3907  524.3095]\n",
      " [   0.        0.        1.    ]]\n"
     ]
    }
   ],
   "source": [
    "K = np.load('Intrinsics_K_trampo.npz')['arr_0']\n",
    "D = np.load('Intrinsics_D_trampo.npz')['arr_0']\n",
    "\n",
    "print(f'Intrinsics: \\n{K[0]} \\n{K[1]} \\n{K[2]} \\n{K[3]} \\n{K[4]} \\n{K[5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save stereo matching frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateImagepoints(Left_Paths:list, Right_Paths:list):\n",
    "    Left_corners, Right_corners = [], []\n",
    "    Left_ids, Right_ids = [], []\n",
    "    Left_Paths_copy, Right_Paths_copy = [], []\n",
    "    for Lname, Rname in zip(Left_Paths, Right_Paths):\n",
    "\n",
    "        _, Lcharuco_corners, Lcharuco_ids = findCorners(im_name=Lname)\n",
    "        _, Rcharuco_corners, Rcharuco_ids = findCorners(im_name=Rname)\n",
    "\n",
    "        if Lcharuco_corners is not None and Rcharuco_corners is not None:\n",
    "            Left_corners.append(Lcharuco_corners)\n",
    "            Left_ids.append(Lcharuco_ids)\n",
    "\n",
    "            Right_corners.append(Rcharuco_corners)\n",
    "            Right_ids.append(Rcharuco_ids)\n",
    "\n",
    "            Left_Paths_copy.append(Lname)\n",
    "            Right_Paths_copy.append(Rname)\n",
    "\n",
    "    return Left_corners, Left_ids, Left_Paths_copy, Right_corners, Right_ids, Right_Paths_copy\n",
    "\n",
    "def getObjectImagePoints(charuco_corners_l, charuco_ids_l, charuco_corners_r, charuco_ids_r):\n",
    "    common_ids = np.intersect1d(charuco_ids_l, charuco_ids_r, assume_unique=True)\n",
    "    if len(common_ids) > 0:\n",
    "        obj_pts = charuco_board.getChessboardCorners()[common_ids.flatten()]\n",
    "        img_pts_l = charuco_corners_l[np.isin(charuco_ids_l, common_ids)].reshape(-1, 1, 2)\n",
    "        img_pts_r = charuco_corners_r[np.isin(charuco_ids_r, common_ids)].reshape(-1, 1, 2)\n",
    "        \n",
    "        return obj_pts, img_pts_l, img_pts_r, common_ids\n",
    "    \n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1-c2: Saved 73 valid frames\n",
      "c1-c3: Saved 0 valid frames\n",
      "c1-c5: Saved 50 valid frames\n",
      "c1-c6: Saved 81 valid frames\n",
      "c1-c7: Saved 60 valid frames\n",
      "c1-c8: Saved 53 valid frames\n",
      "c2-c3: Saved 157 valid frames\n",
      "c2-c5: Saved 58 valid frames\n",
      "c2-c6: Saved 212 valid frames\n",
      "c2-c7: Saved 5 valid frames\n",
      "c2-c8: Saved 33 valid frames\n",
      "c3-c5: Saved 1 valid frames\n",
      "c3-c6: Saved 0 valid frames\n",
      "c3-c7: Saved 0 valid frames\n",
      "c3-c8: Saved 0 valid frames\n",
      "c5-c6: Saved 0 valid frames\n",
      "c5-c7: Saved 93 valid frames\n",
      "c5-c8: Saved 656 valid frames\n",
      "c6-c7: Saved 5 valid frames\n",
      "c6-c8: Saved 0 valid frames\n",
      "c7-c8: Saved 93 valid frames\n"
     ]
    }
   ],
   "source": [
    "intrinsics_extension = 'mp4'\n",
    "\n",
    "detector_params = cv2.aruco.DetectorParameters()\n",
    "video_paths = []\n",
    "\n",
    "for cam1 in cams:\n",
    "    path_cam1 = os.path.join(path, 'intrinsics', cam1)\n",
    "\n",
    "    for cam2 in cams[cams.index(cam1)+1:]:\n",
    "        path_cam2 = os.path.join(path, 'intrinsics', cam2)\n",
    "        video_paths = [os.path.join(path_cam1, os.listdir(path_cam1)[0]), os.path.join(path_cam2, os.listdir(path_cam2)[0])]\n",
    "\n",
    "        output_dir = os.path.join(path, 'stereo', f'{cam1}_{cam2}')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        valid_frame_count = 0  # This counts frames where both cameras detect the board\n",
    "\n",
    "        # Open all video captures\n",
    "        caps = [cv2.VideoCapture(video_path) for video_path in video_paths]\n",
    "\n",
    "        while True:\n",
    "            detections = []\n",
    "            any_failed = False  # Track if any video ended\n",
    "\n",
    "            for i, cap in enumerate(caps):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    any_failed = True  # Stop processing if any video ends\n",
    "                    break\n",
    "\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=detector_params)\n",
    "\n",
    "                if ids is not None and len(ids) >= 10:\n",
    "                    detections.append((i, frame))\n",
    "\n",
    "            if any_failed:\n",
    "                break  # Exit loop if any camera stops\n",
    "\n",
    "            # Save frames only if both cameras detect the board\n",
    "            if len(detections) == 2:\n",
    "                valid_frame_count += 1\n",
    "                for cam_idx, frame in detections:\n",
    "                    frame_filename = os.path.join(output_dir, f\"c{cam_idx}_frame_{valid_frame_count:03d}.png\")\n",
    "                    cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "        print(f'{cam1}-{cam2}: Saved {valid_frame_count} valid frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of all stereo images with 'im_name, img_pts, cam_ timestamp'\n",
    "stereo_images = {'Name':[], 'Camera':[], 'Corners':[], 'Charuco_Corners':[], 'Ids':[]}\n",
    "path_stereo = os.path.join(path, 'stereo')\n",
    "\n",
    "# maximal number of images per camera pair\n",
    "Nmax = 50\n",
    "\n",
    "for cam1 in cams:\n",
    "    for cam2 in cams[cams.index(cam1)+1:]:\n",
    "        im_saved = 0\n",
    "\n",
    "        stereopath = os.path.join(path_stereo, f'{cam1}_{cam2}')\n",
    "        N = len(os.listdir(stereopath))\n",
    "        \n",
    "        number_choice = np.linspace(1, int(N//2), int(N//2))\n",
    "        number_choice = np.round(number_choice).astype(int)\n",
    "\n",
    "        for i in number_choice:\n",
    "                \n",
    "            name1 = f'c0_frame_{i:03d}.png'\n",
    "            name2 = f'c1_frame_{i:03d}.png'\n",
    "            \n",
    "            im1In = name1 in list(os.listdir(stereopath))\n",
    "            im2In = name2 in list(os.listdir(stereopath))\n",
    "                    \n",
    "            if im1In and im2In:\n",
    "                Lret, Lcorners, Lcharuco_corners, Lcharuco_ids = findCorners(im_name=os.path.join(stereopath, name1))\n",
    "                Rret, Rcorners, Rcharuco_corners, Rcharuco_ids = findCorners(im_name=os.path.join(stereopath, name2))\n",
    "\n",
    "                if Lret and Rret:\n",
    "                    _, _, _, common_ids = getObjectImagePoints(Lcharuco_corners, Lcharuco_ids, Rcharuco_corners, Rcharuco_ids)\n",
    "\n",
    "                    if len(common_ids) > 1:\n",
    "                        stereo_images['Name'].append(f'{cam1}_{cam2}_{name1}')\n",
    "                        stereo_images['Camera'].append(int(cam1[-1]))\n",
    "                        stereo_images['Corners'].append(Lcorners)\n",
    "                        stereo_images['Charuco_Corners'].append(Lcharuco_corners)\n",
    "                        stereo_images['Ids'].append(Lcharuco_ids)\n",
    "\n",
    "                        stereo_images['Name'].append(f'{cam1}_{cam2}_{name2}')\n",
    "                        stereo_images['Camera'].append(int(cam2[-1]))\n",
    "                        stereo_images['Corners'].append(Rcorners)\n",
    "                        stereo_images['Charuco_Corners'].append(Rcharuco_corners)\n",
    "                        stereo_images['Ids'].append(Rcharuco_ids)\n",
    "\n",
    "                        im_saved += 1\n",
    "            \n",
    "            if im_saved == Nmax:\n",
    "                break\n",
    "        \n",
    "        print(cam1, cam2, im_saved)\n",
    "    \n",
    "with open('stereo_data_trampo.pkl', 'wb') as f:\n",
    "    pickle.dump(stereo_images, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo initial extrinsic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstereo_data_trampo.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     stereo_images \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('stereo_data_trampo.pkl', 'rb') as f:\n",
    "    stereo_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StereoCalibration(leftparams, rightparams, Left_corners, Left_ids, Right_corners, Right_ids):\n",
    "    StereoParams = {}\n",
    "    ret = False\n",
    "    \n",
    "    k1 = leftparams['Intrinsic']\n",
    "    d1 = leftparams['Distortion']\n",
    "    k2 = rightparams['Intrinsic']\n",
    "    d2 = rightparams['Distortion']\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5)\n",
    "    flags = 0\n",
    "    flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "\n",
    "    obj_points = []  # 3D world coordinates\n",
    "    img_points_left = []  # 2D image coordinates (left camera)\n",
    "    img_points_right = []  # 2D image coordinates (right camera)\n",
    "\n",
    "    for charuco_corners_l, charuco_ids_l, charuco_corners_r, charuco_ids_r in zip(Left_corners, Left_ids, Right_corners, Right_ids):\n",
    "        # Find common detected corners (based on Charuco IDs)\n",
    "        obj_pts, img_pts_l, img_pts_r, common_ids = getObjectImagePoints(charuco_corners_l, charuco_ids_l, charuco_corners_r, charuco_ids_r)\n",
    "        \n",
    "        obj_points.append(obj_pts)\n",
    "        img_points_left.append(img_pts_l)\n",
    "        img_points_right.append(img_pts_r)\n",
    "\n",
    "    if len(img_points_left) > 1 and len(img_points_right) > 1:\n",
    "        (ret, K1, D1, K2, D2, R, t, E, F) = cv2.stereoCalibrate(obj_points, img_points_left, img_points_right, k1, d1, k2, d2, image_size, criteria=criteria, flags=flags)\n",
    "    \n",
    "        T = np.vstack((np.hstack((R,t)),np.array([0,0,0,1])))\n",
    "        \n",
    "        StereoParams['Transformation'] = T\n",
    "        StereoParams['Essential'] = E\n",
    "        StereoParams['Fundamental'] = F\n",
    "        StereoParams['MeanError'] = ret\n",
    "        \n",
    "    return ret, StereoParams\n",
    "\n",
    "def SaveParameters(camL, camR, Stereo_Params, Left_Params, Right_Params):\n",
    "    Parameters = Stereo_Params.copy()  # Ensure we're not modifying the original dictionary\n",
    "\n",
    "    for Lkey in Left_Params.keys():\n",
    "        name = 'L_'+str(Lkey)\n",
    "        Parameters[name] = Left_Params[Lkey]\n",
    "        \n",
    "    for Rkey in Right_Params.keys():\n",
    "        name = 'R_'+str(Rkey)\n",
    "        Parameters[name] = Right_Params[Rkey]\n",
    "\n",
    "    # Remove imgpoints if they exist in Left_Params and Right_Params\n",
    "    Parameters = {k: v for k, v in Parameters.items() if k not in ['L_Imgpoints', 'R_Imgpoints']}\n",
    "\n",
    "    # Save the Parameters dictionary into an npz file\n",
    "    file = f'{camL}_{camR}_parameters.npz'\n",
    "    np.savez(file, **Parameters)\n",
    "    npz = dict(np.load(file))\n",
    "    np.savez(file, **npz)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c6 c7\n",
      "Transformation Matrix:\n",
      "[[   -0.3904     0.8052     0.4464 -1259.0967]\n",
      " [    0.4946    -0.2255     0.8393  2213.5227]\n",
      " [    0.7765     0.5485    -0.3102  3367.7477]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "c6 c8\n",
      "Not enough images \n",
      "\n",
      "c7 c8\n",
      "Transformation Matrix:\n",
      "[[   0.7521   -0.6315   -0.1883  668.2265]\n",
      " [   0.3447    0.6205   -0.7044 2096.9338]\n",
      " [   0.5617    0.4649    0.6843  535.2671]\n",
      " [   0.        0.        0.        1.    ]]\n"
     ]
    }
   ],
   "source": [
    "path_stereo = os.path.join(path, 'stereo')\n",
    "\n",
    "for camL in cams[4:]:\n",
    "    \n",
    "    Left_Params = {}\n",
    "    Left_Params['Intrinsic'] = K[cams.index(camL)]\n",
    "    Left_Params['Distortion'] = D[cams.index(camL)]\n",
    "\n",
    "    for camR in cams[cams.index(camL)+1:]:\n",
    "        print(camL, camR)\n",
    "        stereopath = os.path.join(path_stereo, f'{camL}_{camR}')\n",
    "\n",
    "        Left_Paths = [os.path.join(stereopath, fname) for fname in list(os.listdir(stereopath)) if fname.split('_')[0] == 'c0']\n",
    "        Right_Paths = [os.path.join(stereopath, fname) for fname in list(os.listdir(stereopath)) if fname.split('_')[0] == 'c1']\n",
    "        Right_Params = {}\n",
    "        \n",
    "        if len(Left_Paths) >= 1 and len(Right_Paths) >= 1:\n",
    "            Left_corners, Left_ids, Left_Paths, Right_corners, Right_ids, Right_Paths = GenerateImagepoints(Left_Paths, Right_Paths)\n",
    "            if len(Left_corners) >= 1 and len(Right_corners) >= 1:\n",
    "\n",
    "                Right_Params['Intrinsic'] = K[cams.index(camR)]\n",
    "                Right_Params['Distortion'] = D[cams.index(camR)]\n",
    "             \n",
    "                ret, Stereo_Params = StereoCalibration(Left_Params, Right_Params, Left_corners, Left_ids, Right_corners, Right_ids)\n",
    "                if ret:\n",
    "                    print('Transformation Matrix:')\n",
    "                    print(Stereo_Params['Transformation'])\n",
    "\n",
    "                    SaveParameters(camL, camR, Stereo_Params, Left_Params, Right_Params)\n",
    "                else:\n",
    "                    print('Not enough corners', '\\n')\n",
    "            else:\n",
    "                print('Not enough corners', '\\n')\n",
    "        else:\n",
    "            print('Not enough images', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_c2 = np.load('c1_c2_parameters.npz')['Transformation']\n",
    "c1_c5 = np.load('c1_c5_parameters.npz')['Transformation']\n",
    "c1_c6 = np.load('c1_c6_parameters.npz')['Transformation']\n",
    "c1_c8 = np.load('c1_c8_parameters.npz')['Transformation']\n",
    "c2_c3 = np.load('c2_c3_parameters.npz')['Transformation']\n",
    "c2_c6 = np.load('c2_c6_parameters.npz')['Transformation']\n",
    "# c3_c5 = np.load('c3_c5_parameters.npz')['Transformation']\n",
    "# c5_c8 = np.load('c5_c8_parameters.npz')['Transformation']\n",
    "c6_c7 = np.load('c6_c7_parameters.npz')['Transformation']\n",
    "c7_c8 = np.load('c7_c8_parameters.npz')['Transformation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_name(var, scope=globals()):\n",
    "    return [name for name, value in scope.items() if value is var][0]\n",
    "\n",
    "def compare_transfo(T12, T23, T13):\n",
    "    print(f'Original {var_name(T13)}')\n",
    "    print(T13)\n",
    "    T13_calc = T12 @ T23\n",
    "    print(f'Calculated {var_name(T13)}')\n",
    "    print(T13_calc)\n",
    "    print('Calculated I')\n",
    "    print(np.linalg.inv(T13_calc) @ T13, '\\n')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original c1_c6\n",
      "[[   -0.9331    -0.2087     0.2928  -412.6195]\n",
      " [    0.2952     0.0203     0.9552 -1752.1784]\n",
      " [   -0.2053     0.9778     0.0426  2721.545 ]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "Calculated c1_c6\n",
      "[[  -0.7354    0.5277    0.4251 -515.674 ]\n",
      " [   0.6381    0.7504    0.1724  303.7453]\n",
      " [  -0.228     0.398    -0.8886 3643.5025]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "Calculated I\n",
      "[[    0.9214    -0.0565     0.3844 -1177.4193]\n",
      " [   -0.3526     0.2943     0.8883 -1855.3634]\n",
      " [   -0.1634    -0.954      0.2513   508.6826]\n",
      " [    0.         0.         0.         1.    ]] \n",
      "\n",
      "Original c1_c8\n",
      "[[  -0.6748    0.7039    0.2217 -381.9901]\n",
      " [  -0.4792   -0.1894   -0.8571 1915.0585]\n",
      " [  -0.5613   -0.6846    0.4651 1934.941 ]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "Calculated c1_c8\n",
      "[[  -0.2034   -0.9631   -0.1761  107.5669]\n",
      " [   0.6568   -0.0008   -0.7541 3071.8963]\n",
      " [   0.7261   -0.269     0.6328 5309.9665]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "Calculated I\n",
      "[[   -0.585     -0.7646    -0.2703 -3110.8952]\n",
      " [    0.8013    -0.4936    -0.3379  1380.4312]\n",
      " [    0.125     -0.4143     0.9015 -1177.0633]\n",
      " [    0.         0.         0.         1.    ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_transfo(c1_c2, c2_c6, c1_c6)\n",
    "\n",
    "c6_c8 = c6_c7 @ c7_c8\n",
    "compare_transfo(c1_c6, c6_c8, c1_c8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D reprojection error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to project 3D points to 2D\n",
    "def project_points(points_3d, projMat, K, D):\n",
    "    rvec, _ = cv2.Rodrigues(projMat[0:3,0:3])\n",
    "    projected_2d, _ = cv2.projectPoints(points_3d, rvec, projMat[0:3,3], K, D)\n",
    "    return projected_2d.squeeze()\n",
    "\n",
    "# Compute RMSE\n",
    "def compute_rmse(original_pts, points_3d, projMat, K, D):\n",
    "    projected_pts = project_points(points_3d, projMat, K, D)\n",
    "    error = np.linalg.norm(original_pts - projected_pts, axis=1)  # Euclidean distance per point\n",
    "    rmse = np.sqrt(np.mean(error**2))  # Compute RMSE\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[   -0.548     -0.3052     0.7788 -1616.1915]\n",
      " [    0.3535     0.7593     0.5463 -1075.6122]\n",
      " [   -0.7581     0.5747    -0.3082  2708.2644]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "[[   0.1536    0.3643    0.9185  599.4048]\n",
      " [  -0.776    -0.5311    0.3403  655.6455]\n",
      " [   0.6118   -0.765     0.2011 2491.6402]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "[[   -0.9003    -0.2442     0.3603 -1511.0614]\n",
      " [   -0.4162     0.2407    -0.8768  2200.7504]\n",
      " [    0.1274    -0.9394    -0.3183  3113.172 ]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "[[   -0.9331    -0.2087     0.2928  -412.6195]\n",
      " [    0.2952     0.0203     0.9552 -1752.1784]\n",
      " [   -0.2053     0.9778     0.0426  2721.545 ]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "[[   0.4884   -0.5437   -0.6825 1286.5337]\n",
      " [   0.6365    0.757    -0.1475 1138.061 ]\n",
      " [   0.5969   -0.3624    0.7158 5287.8902]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "[[  -0.6748    0.7039    0.2217 -381.9901]\n",
      " [  -0.4792   -0.1894   -0.8571 1915.0585]\n",
      " [  -0.5613   -0.6846    0.4651 1934.941 ]\n",
      " [   0.        0.        0.        1.    ]]\n"
     ]
    }
   ],
   "source": [
    "Tcam1 = np.eye((4))\n",
    "Tcam6 = c1_c6\n",
    "Tcam5 = c1_c5\n",
    "Tcam2 = c1_c2\n",
    "Tcam3 = Tcam2 @ c2_c3\n",
    "Tcam7 = Tcam6 @ c6_c7\n",
    "Tcam8 = c1_c8\n",
    "\n",
    "projMat = [Tcam1, Tcam2, Tcam3, Tcam5, Tcam6, Tcam7, Tcam8]\n",
    "\n",
    "for mat in projMat:\n",
    "    print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO for extrinsic parameters (with Bundle adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,)\n",
      "(60, 42)\n",
      "(42,)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "num_cameras = 7\n",
    "num_params_per_cam = 6\n",
    "total_params = num_cameras * num_params_per_cam\n",
    "n_particles = 60  # Number of particles\n",
    "options = {'c1': 1.5, 'c2': 1.5, 'w': 0.7} #{'c1': 2.05, 'c2': 2.05, 'w': 0.729} # PSO Hyperparameters\n",
    "\n",
    "projMat = np.load('Extrinsics_optimized_3.npz')['arr_0']\n",
    "\n",
    "init_params = []\n",
    "for mat in projMat:\n",
    "    rvec, _ = cv2.Rodrigues(mat[0:3,0:3])\n",
    "    rvec = rvec.squeeze()\n",
    "    params = [rvec[0], rvec[1], rvec[2], mat[0,3], mat[1,3], mat[2,3]]\n",
    "    init_params.extend(params)\n",
    "\n",
    "init_params = np.array(init_params, dtype=np.float64)\n",
    "init_pos = np.tile(init_params, (n_particles,1))\n",
    "print(init_params.shape)\n",
    "print(init_pos.shape)\n",
    "\n",
    "# Define parameter bounds\n",
    "lower_bounds = [-2*np.pi, -2*np.pi, -2*np.pi, -5000, -5000, -5000]\n",
    "upper_bounds = [2*np.pi, 2*np.pi, 2*np.pi, 5000, 5000, 6000]\n",
    "\n",
    "param_bounds = (np.tile(lower_bounds, num_cameras), np.tile(upper_bounds, num_cameras))\n",
    "print(param_bounds[0].shape)\n",
    "\n",
    "print(np.all(param_bounds[0] <= init_pos[0]))\n",
    "print(np.all(init_pos[0] <= param_bounds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(params):\n",
    "    errors = np.empty((n_particles,))\n",
    "    params = np.array(params)\n",
    "\n",
    "    for n in range(n_particles):\n",
    "        projMat = np.empty((num_cameras+1, 3, 4))\n",
    "        projMat[0] = np.hstack((np.eye((3)), np.zeros((3,1))))\n",
    "\n",
    "        for cam_idx in range(num_cameras):\n",
    "            cam_params = params[n][cam_idx * num_params_per_cam : (cam_idx + 1) * num_params_per_cam]\n",
    "            r1, r2, r3, t1, t2, t3 = cam_params\n",
    "            rvec = np.array([r1, r2, r3])\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            t = np.array([t1, t2, t3]).reshape((3,1))\n",
    "            projMat[cam_idx+1] = np.hstack((R, t))  #[cam_idx+1]\n",
    "\n",
    "        RMSE = []\n",
    "        # Loop on stereo images checkberboard points\n",
    "        for i in range(0, len(stereo_images['Camera']) - 1, 2):\n",
    "            j = i+1 # stereo image is the next one\n",
    "\n",
    "            pts1_im = stereo_images['Charuco_Corners'][i].squeeze()\n",
    "            pts2_im = stereo_images['Charuco_Corners'][j].squeeze()\n",
    "\n",
    "            Lids = stereo_images['Ids'][i].squeeze()\n",
    "            Rids = stereo_images['Ids'][j].squeeze()\n",
    "\n",
    "            c1 = cams.index(f'c{stereo_images['Camera'][i]}')\n",
    "            c2 = cams.index(f'c{stereo_images['Camera'][j]}')\n",
    "\n",
    "            undist_pts1 = cv2.undistortPoints(pts1_im, K[c1], D[c1]).reshape(-1, 2)  # Shape (2, N)\n",
    "            undist_pts2 = cv2.undistortPoints(pts2_im, K[c2], D[c2]).reshape(-1, 2)  # Shape (2, N)\n",
    "\n",
    "            obj_pts, img_pts_l, img_pts_r, common_ids = getObjectImagePoints(undist_pts1, Lids, undist_pts2, Rids)\n",
    "\n",
    "            ids_to_keepL = [list(Lids).index(t) for t in common_ids]\n",
    "            ids_to_keepR = [list(Rids).index(t) for t in common_ids]\n",
    "\n",
    "            img_pts_l, img_pts_r = img_pts_l.squeeze(), img_pts_r.squeeze()\n",
    "\n",
    "            # Perform triangulation\n",
    "            pts_4d = cv2.triangulatePoints(projMat[c1], projMat[c2], img_pts_l.T, img_pts_r.T)\n",
    "            points_3d = pts_4d[:3, :] / pts_4d[3, :]  # Shape (3, N)\n",
    "            points_3d = points_3d.T  # Shape (N, 3)\n",
    "\n",
    "            # Compute RMSE for both cameras\n",
    "            rmse1 = compute_rmse(pts1_im[ids_to_keepL], points_3d, projMat[c1], K[c1], D[c1])\n",
    "            rmse2 = compute_rmse(pts2_im[ids_to_keepR], points_3d, projMat[c2], K[c2], D[c2])\n",
    "\n",
    "            RMSE.append(rmse1)\n",
    "            RMSE.append(rmse2)\n",
    "\n",
    "        errors[n] = np.mean(RMSE) #+ np.max(RMSE)   # OPTIONAL: add max error to cost function\n",
    "    \n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:54:00,332 - pyswarms.single.global_best - INFO - Optimize for 2000 iters with {'c1': 1.5, 'c2': 1.5, 'w': 0.7}\n",
      "pyswarms.single.global_best: 100%|██████████|2000/2000, best_cost=8.41\n",
      "2025-03-28 20:10:49,739 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 8.41150188446045, best pos: [    0.1342     0.4142    -0.6978  1452.0612  -595.7068  3208.5055\n",
      "    -0.4775     1.0714    -1.4878  -425.9488 -1267.6664  5593.3008\n",
      "    -0.1449     0.5425    -1.8993 -4172.4578  4938.328   4958.2298\n",
      "     0.7131     2.9304    -0.6542 -2945.081   1637.1761  3869.3454\n",
      "     0.9303    -2.8937    -0.0815   490.6938 -1614.5824 -1634.6394\n",
      "    -0.1349     0.0269    -2.1777  -520.9657  3531.7928  4463.8015\n",
      "     0.9667    -3.2931    -3.489   1165.8387  -600.8255 -3669.6917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Reprojection Error: 8.41150188446045 pixels\n"
     ]
    }
   ],
   "source": [
    "# Run PSO to optimize calibration parameters\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=n_particles, dimensions=total_params, options=options, bounds=param_bounds, init_pos=init_pos)\n",
    "best_error, best_params = optimizer.optimize(fun, iters=2000)\n",
    "print(f\"Best Reprojection Error: {best_error} pixels\")\n",
    "\n",
    "# Extract optimized parameters for each camera\n",
    "optimized_params = np.split(best_params, num_cameras)\n",
    "\n",
    "plot_cost_history(cost_history=optimizer.cost_history)\n",
    "#plt.savefig('Figure_1_pso_cost_3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 1 Optimized Camera Matrix:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Camera 2 Optimized Camera Matrix:\n",
      " [[   0.6889    0.648     0.3248 1452.0612]\n",
      " [  -0.5955    0.7614   -0.2561 -595.7068]\n",
      " [  -0.4133   -0.017     0.9104 3208.5055]]\n",
      "Camera 3 Optimized Camera Matrix:\n",
      " [[   -0.2345     0.5566     0.797   -425.9488]\n",
      " [   -0.9324     0.1034    -0.3465 -1267.6664]\n",
      " [   -0.2752    -0.8243     0.4947  5593.3008]]\n",
      "Camera 4 Optimized Camera Matrix:\n",
      " [[   -0.391      0.8515     0.3493 -4172.4578]\n",
      " [   -0.9076    -0.2935    -0.3002  4938.328 ]\n",
      " [   -0.1531    -0.4344     0.8876  4958.2298]]\n",
      "Camera 5 Optimized Camera Matrix:\n",
      " [[   -0.8917     0.4503    -0.0452 -2945.081 ]\n",
      " [    0.4268     0.8035    -0.4151  1637.1761]\n",
      " [   -0.1506    -0.3894    -0.9087  3869.3454]]\n",
      "Camera 6 Optimized Camera Matrix:\n",
      " [[   -0.8082    -0.5781    -0.1122   490.6938]\n",
      " [   -0.5835     0.8118     0.0201 -1614.5824]\n",
      " [    0.0795     0.0817    -0.9935 -1634.6394]]\n",
      "Camera 7 Optimized Camera Matrix:\n",
      " [[  -0.5679    0.8161    0.1072 -520.9657]\n",
      " [  -0.8185   -0.5737    0.0313 3531.7928]\n",
      " [   0.087    -0.07      0.9937 4463.8015]]\n",
      "Camera 8 Optimized Camera Matrix:\n",
      " [[    0.2127    -0.81       0.5464  1165.8387]\n",
      " [    0.5923     0.5517     0.5873  -600.8255]\n",
      " [   -0.7772     0.1987     0.5971 -3669.6917]]\n"
     ]
    }
   ],
   "source": [
    "extrinsics = []\n",
    "extrinsics.append(np.hstack((np.eye((3)), np.zeros((3,1)))))\n",
    "\n",
    "for cam_idx in range(num_cameras):\n",
    "    r1, r2, r3, t1, t2, t3 = optimized_params[cam_idx]\n",
    "    rvec = np.array([r1,r2,r3], dtype=np.float64)\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    t = np.array([t1,t2,t3], dtype=np.float64).reshape((3,1))\n",
    "\n",
    "    optimized_camera_matrix = np.hstack((R,t))\n",
    "    extrinsics.append(optimized_camera_matrix)\n",
    "\n",
    "for cam_idx, cam_mat in enumerate(extrinsics):\n",
    "    print(f\"Camera {cam_idx+1} Optimized Camera Matrix:\\n\", cam_mat)\n",
    "\n",
    "np.savez('Extrinsics_optimized_4.npz', extrinsics[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative error on matrices multiplication (Total transfo = I ?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 calc: \n",
      " [[   -0.8917     0.4503    -0.0452 -2945.081 ]\n",
      " [    0.4268     0.8035    -0.4151  1637.1761]\n",
      " [   -0.1506    -0.3894    -0.9087  3869.3454]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "T5: \n",
      " [[   -0.8917     0.4503    -0.0452 -2945.081 ]\n",
      " [    0.4268     0.8035    -0.4151  1637.1761]\n",
      " [   -0.1506    -0.3894    -0.9087  3869.3454]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "Cumulative error: \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "T = []\n",
    "\n",
    "for mat in extrinsics:\n",
    "    M = np.vstack((mat, np.array([0,0,0,1])))\n",
    "    T.append(M)\n",
    "\n",
    "T_next = []\n",
    "for i in range(len(T) - 1):\n",
    "    T_next.append(np.linalg.inv(T[i]) @ T[i+1])\n",
    "\n",
    "T5_calc = T_next[0] @ T_next[1] @ T_next[2] @ T_next[3]\n",
    "\n",
    "print('T5 calc: \\n', T5_calc)\n",
    "print('T5: \\n', T[4])\n",
    "\n",
    "I_calc = T5_calc @ np.linalg.inv(T[4])\n",
    "print('Cumulative error: \\n', np.abs(I_calc - np.eye(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D visualization of original and projected points onto images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circles(img, pts_2d_original, pts_2d_projected, text=True):\n",
    "\n",
    "    pts_2d_original = pts_2d_original.reshape(-1,2)\n",
    "    pts_2d_projected = pts_2d_projected.reshape(-1,2)\n",
    "    \n",
    "    for p in range(len(pts_2d_original)):\n",
    "        x_orig, y_orig = map(int, pts_2d_original[p])  # Original 2D point\n",
    "        cv2.circle(img, (x_orig, y_orig), 8, (255, 0, 0), -1)\n",
    "\n",
    "        if pts_2d_projected is not None:\n",
    "            x_proj, y_proj = map(int, pts_2d_projected[p])  # Reprojected 3D point\n",
    "            cv2.circle(img, (x_proj, y_proj), 8, (0, 255, 0), -1)\n",
    "            cv2.line(img, (x_orig, y_orig), (x_proj, y_proj), (0, 255, 255), 2)\n",
    "\n",
    "        if text:\n",
    "            # Add labels\n",
    "            cv2.putText(img, str(p + 1), (x_orig + 10, y_orig), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.6, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(img, str(p + 1), (x_proj + 10, y_proj), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1-c2 5.35145\n",
      "c1-c3 nan\n",
      "c1-c5 6.7054524\n",
      "c1-c6 9.101836\n",
      "c1-c7 nan\n",
      "c1-c8 12.525467\n",
      "c2-c3 6.508746\n",
      "c2-c5 nan\n",
      "c2-c6 35.759777\n",
      "c2-c7 nan\n",
      "c2-c8 nan\n",
      "c3-c5 2.2967505\n",
      "c3-c6 nan\n",
      "c3-c7 nan\n",
      "c3-c8 nan\n",
      "c5-c6 nan\n",
      "c5-c7 nan\n",
      "c5-c8 0.8153839\n",
      "c6-c7 3.1119726\n",
      "c6-c8 nan\n",
      "c7-c8 5.6156445\n"
     ]
    }
   ],
   "source": [
    "dir_images = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\video_test\\stereo'\n",
    "\n",
    "projMat = extrinsics\n",
    "\n",
    "RMSE = []\n",
    "rmse_per_cam = {'c1-c2':[], 'c1-c3':[], 'c1-c5':[], 'c1-c6':[], 'c1-c7':[], 'c1-c8':[],\n",
    "                'c2-c3':[], 'c2-c5':[], 'c2-c6':[], 'c2-c7':[], 'c2-c8':[],\n",
    "                'c3-c5':[], 'c3-c6':[], 'c3-c7':[], 'c3-c8':[],\n",
    "                'c5-c6':[], 'c5-c7':[], 'c5-c8':[], 'c6-c7':[], 'c6-c8':[], 'c7-c8':[]}\n",
    "\n",
    "fig, axs = plt.subplots(6, 6, figsize=(20,14))\n",
    "axs = axs.flat\n",
    "k = 0\n",
    "\n",
    "for i in range(0, len(stereo_images['Camera']) - 1, 2):\n",
    "    j = i+1 # stereo image is the next one\n",
    "\n",
    "    pts1_im = stereo_images['Charuco_Corners'][i].squeeze()\n",
    "\n",
    "    pts2_im = stereo_images['Charuco_Corners'][j].squeeze()\n",
    "\n",
    "    Lids = stereo_images['Ids'][i].squeeze()\n",
    "    Rids = stereo_images['Ids'][j].squeeze()\n",
    "\n",
    "    c1 = cams.index(f'c{stereo_images['Camera'][i]}')\n",
    "    c2 = cams.index(f'c{stereo_images['Camera'][j]}')\n",
    "    \n",
    "    undist_pts1 = cv2.undistortPoints(pts1_im, K[c1], D[c1]).reshape(-1, 2)  # Shape (2, N)\n",
    "    undist_pts2 = cv2.undistortPoints(pts2_im, K[c2], D[c2]).reshape(-1, 2)  # Shape (2, N)\n",
    "\n",
    "    obj_pts, img_pts_l, img_pts_r, common_ids = getObjectImagePoints(undist_pts1, Lids, undist_pts2, Rids)\n",
    "\n",
    "    ids_to_keepL = [list(Lids).index(t) for t in common_ids]\n",
    "    ids_to_keepR = [list(Rids).index(t) for t in common_ids]\n",
    "\n",
    "    img_pts_l, img_pts_r = img_pts_l.squeeze(), img_pts_r.squeeze()\n",
    "\n",
    "    # Perform triangulation\n",
    "    pts_4d = cv2.triangulatePoints(projMat[c1], projMat[c2], img_pts_l.T, img_pts_r.T)\n",
    "    points_3d = pts_4d[:3, :] / pts_4d[3, :]  # Shape (3, N)\n",
    "    points_3d = points_3d.T  # Shape (N, 3)\n",
    "\n",
    "    img_path1 = os.path.join(dir_images, stereo_images['Name'][i][0:5], stereo_images['Name'][i][6:])\n",
    "    img_path2 = os.path.join(dir_images, stereo_images['Name'][j][0:5], stereo_images['Name'][j][6:])\n",
    "\n",
    "    # Visualize original and reprojected points (image 1)\n",
    "    img = cv2.imread(img_path1)\n",
    "\n",
    "    pts_2d_projected, _ = cv2.projectPoints(points_3d, projMat[c1][0:3,0:3], projMat[c1][0:3,3], K[c1], D[c1])\n",
    "    pts_2d_projected = pts_2d_projected.squeeze()\n",
    "    rmse1 = compute_rmse(pts1_im[ids_to_keepL], points_3d, projMat[c1], K[c1], D[c1])\n",
    "\n",
    "    if i % 8 == 0:\n",
    "        img = draw_circles(img, pts1_im[ids_to_keepL], pts_2d_projected)\n",
    "        axs[k].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[k].axis('off')\n",
    "        axs[k].set_title(f'{stereo_images['Name'][i]} RMSE = {rmse1:.2f}', fontsize=8)\n",
    "\n",
    "    # Visualize original and reprojected points (image 2)\n",
    "    img = cv2.imread(img_path2)\n",
    "    \n",
    "    pts_2d_projected, _ = cv2.projectPoints(points_3d, projMat[c2][0:3,0:3], projMat[c2][0:3,3], K[c2], D[c2])\n",
    "    pts_2d_projected = pts_2d_projected.squeeze()\n",
    "    rmse2 = compute_rmse(pts2_im[ids_to_keepR], points_3d, projMat[c2], K[c2], D[c2])\n",
    "\n",
    "    if i % 8 == 0:\n",
    "        img = draw_circles(img, pts2_im[ids_to_keepR], pts_2d_projected)\n",
    "        axs[k+1].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[k+1].axis('off')\n",
    "        axs[k+1].set_title(f'{stereo_images['Name'][j]} RMSE = {rmse2:.2f}', fontsize=8)\n",
    "        k += 2\n",
    "\n",
    "    rmse_per_cam[f'{cams[c1]}-{cams[c2]}'] += [rmse1, rmse2]\n",
    "\n",
    "fig.suptitle(\"Original 2D Points (Blue) vs. Projected 3D Points (Green)\")\n",
    "fig.tight_layout()\n",
    "plt.savefig('Figure_reprojection_4.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "for key, vals in rmse_per_cam.items():\n",
    "    print(key, np.mean(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D visualization of cameras in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(ax, T, label=\"Frame\", length=100.0):\n",
    "    \"\"\"Plots a 3D reference frame with arrows for X, Y, and Z axes.\"\"\"\n",
    "    origin = T[:3, 3]  # Extract translation (position)\n",
    "    R = T[:3, :3]      # Extract rotation matrix (orientation)\n",
    "\n",
    "    # Define the x, y, z unit vectors from the rotation matrix\n",
    "    x_axis = R[:, 0] * length  # X-direction\n",
    "    y_axis = R[:, 1] * length  # Y-direction\n",
    "    z_axis = R[:, 2] * length  # Z-direction\n",
    "\n",
    "    # Plot arrows for the axes\n",
    "    ax.quiver(*origin, *x_axis, color='r', arrow_length_ratio=0.3)  # X-axis (Red)\n",
    "    ax.quiver(*origin, *y_axis, color='g', arrow_length_ratio=0.3)  # Y-axis (Green)\n",
    "    ax.quiver(*origin, *z_axis, color='b', arrow_length_ratio=0.3)  # Z-axis (Blue)\n",
    "\n",
    "    # Label the frame\n",
    "    ax.text(*origin, label, fontsize=12, color='black')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frames\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i, T in enumerate(extrinsics):\n",
    "    T = np.vstack((T, np.array([0,0,0,1])))\n",
    "    plot_frame(ax, T, label=f'Camera {i+1}')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.title(\"3D Reference Frames\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trampo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
