{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration tests\n",
    "### Pose2Sim calibration.py functions\n",
    "### Data projet Cobotique\n",
    "\n",
    "Auteurs : Léa Drolet-Roy\n",
    "\n",
    "Création : 2025-02-18\n",
    "\n",
    "Dernière modification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import pyswarms as ps\n",
    "from pyswarms.utils.plotters import plot_cost_history\n",
    "\n",
    "from Calibration import calibration as cali\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKERBOARD = (7,4)\n",
    "SQUARE_SIZE = 48\n",
    "\n",
    "cams = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6']\n",
    "time_threshold = 15\n",
    "\n",
    "path = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique'\n",
    "u101 = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\u101'\n",
    "u102 = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\u102'\n",
    "\n",
    "extrinsics_corners_nb = CHECKERBOARD\n",
    "extrinsics_square_size = SQUARE_SIZE\n",
    "\n",
    "objpoints = np.zeros((extrinsics_corners_nb[0] * extrinsics_corners_nb[1], 3), np.float32)\n",
    "objpoints[:, :2] = np.mgrid[0:extrinsics_corners_nb[0], 0:extrinsics_corners_nb[1]].T.reshape(-1, 2)\n",
    "objpoints[:, :2] = objpoints[:, 0:2] * extrinsics_square_size\n",
    "\n",
    "cal = cali(CHECKERBOARD, SQUARE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find images where we see the checkerboard, for individual cameras\n",
    "def save_images_checkerboard(path, dir, cam):\n",
    "    for fname in os.listdir(os.path.join(dir, cam)):\n",
    "        savepath = os.path.join(path, 'calibration', 'intrinsics', cam)\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        savename = dir[-4:] + '_' + cam + fname\n",
    "        # if savename not in os.listdir(os.path.join(path, 'calibration', 'intrinsics', cam)):\n",
    "        ret, img, _ = cal.findCorners(os.path.join(dir, cam, fname), subpix = False)\n",
    "\n",
    "        if ret == True:\n",
    "            cv2.imwrite(os.path.join(savepath, savename), img)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cam in os.listdir(u101):\n",
    "#     save_images_checkerboard(path, u101, cam)\n",
    "    \n",
    "# for cam in os.listdir(u102):\n",
    "#     save_images_checkerboard(path, u102, cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics_config_dict = {'calculate_intrinsics':True, 'overwrite_intrinsics':True, 'show_detection_intrinsics':False, 'intrinsics_method':'board',\n",
    "                          'intrinsics_extension': 'png', 'intrinsics_corners_nb':CHECKERBOARD, 'intrinsics_square_size':SQUARE_SIZE,\n",
    "                          'board': {'intrinsics_extension': 'png', 'show_reprojection_error': True,\n",
    "                                    'intrinsics_corners_nb': CHECKERBOARD, 'intrinsics_square_size':SQUARE_SIZE}}\n",
    "\n",
    "extrinsics_config_dict = {'calculate_extrinsics':True, 'show_detection_extrinsics':False, 'extrinsics_method':'board',\n",
    "                          'extrinsics_extension': 'png', 'extrinsics_corners_nb':CHECKERBOARD, 'extrinsics_square_size':SQUARE_SIZE,\n",
    "                          'board': {'extrinsics_extension': 'png', 'show_reprojection_error': True,\n",
    "                                    'extrinsics_corners_nb': CHECKERBOARD, 'extrinsics_square_size':SQUARE_SIZE}}\n",
    "\n",
    "calib_dir = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\"\n",
    "image_size = (1280, 720)\n",
    "\n",
    "# ret, C, S, D, K, R, T = calibration.calibrate_intrinsics(calib_dir, intrinsics_config_dict)\n",
    "# ret, C, S, D, K, R, T = cal.calibrate_intrinsics(calib_dir, image_size, camera_matrix)\n",
    "# print(f'reproj error (mm): {ret} \\nCam: {C} \\nImage Size: {S} \\nIntrinsics: \\n{K[0]} \\n{K[1]} \\n{K[2]} \\n{K[3]} \\n{K[4]} \\n{K[5]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array(K)\n",
    "np.savez('Intrinsics_K_final.npz', K)\n",
    "\n",
    "D = np.array(D)\n",
    "np.savez('Intrinsics_D_final.npz', D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsics: \n",
      "[[648.4489   0.     648.7351]\n",
      " [  0.     649.7999 362.77  ]\n",
      " [  0.       0.       1.    ]] \n",
      "[[655.7549   0.     657.0469]\n",
      " [  0.     657.8988 357.1172]\n",
      " [  0.       0.       1.    ]] \n",
      "[[653.0931   0.     643.5985]\n",
      " [  0.     653.7393 362.3068]\n",
      " [  0.       0.       1.    ]] \n",
      "[[641.12     0.     659.4241]\n",
      " [  0.     637.8964 368.091 ]\n",
      " [  0.       0.       1.    ]] \n",
      "[[645.08     0.     652.0756]\n",
      " [  0.     646.7413 361.2488]\n",
      " [  0.       0.       1.    ]] \n",
      "[[649.8124   0.     657.3696]\n",
      " [  0.     650.0296 366.7623]\n",
      " [  0.       0.       1.    ]]\n"
     ]
    }
   ],
   "source": [
    "K = np.load('saved_cobotique/Intrinsics_K_final.npz')['arr_0']\n",
    "D = np.load('saved_cobotique/Intrinsics_D_final.npz')['arr_0']\n",
    "\n",
    "print(f'Intrinsics: \\n{K[0]} \\n{K[1]} \\n{K[2]} \\n{K[3]} \\n{K[4]} \\n{K[5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33992838541666665\n",
      "0.8218532986111111\n",
      "0.8710416666666667\n",
      "0.29476128472222224\n",
      "0.7610709635416667\n",
      "0.7409201388888889\n"
     ]
    }
   ],
   "source": [
    "angle_threshold = 60 #degrees\n",
    "coverage_threshold = (0.01, 0.99)\n",
    "image_size = (1280, 720)\n",
    "\n",
    "for i, cam in enumerate(cams):\n",
    "    area = cal.refine_image_selection(calib_dir, 'intrinsics_refine', cam, K[i], D[i], image_size, angle_threshold, coverage_threshold)\n",
    "    print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stereo = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\stereo_confirmed'\n",
    "path_intrinsics = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed'\n",
    "\n",
    "# cal.find_matching_images(path, 'u101', cams, time_threshold, path_stereo, path_intrinsics)\n",
    "# cal.find_matching_images(path, 'u102', cams, time_threshold, path_stereo, path_intrinsics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo calibration with matching images for each pair of cameras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop on possible camera pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 c2\n",
      "Not enough images \n",
      "\n",
      "c1 c3\n",
      "Not enough images \n",
      "\n",
      "c1 c4\n",
      "Reprojection Error Left:  0.7715\n",
      "Reprojection Error Right: 1.3015\n",
      "Transformation Matrix:\n",
      "[[   0.4834    0.4534   -0.7488  878.467 ]\n",
      " [  -0.3757    0.8801    0.2903 -165.104 ]\n",
      " [   0.7907    0.1409    0.5958   32.3176]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "c1 c5\n",
      "Reprojection Error Left:  0.8343\n",
      "Reprojection Error Right: 0.7774\n",
      "Transformation Matrix:\n",
      "[[    0.351     -0.4999     0.7917 -1836.7874]\n",
      " [    0.4327     0.8365     0.3363  -809.4149]\n",
      " [   -0.8304     0.2245     0.5099  1044.6748]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "c1 c6\n",
      "Reprojection Error Left:  0.7373\n",
      "Reprojection Error Right: 0.8058\n",
      "Transformation Matrix:\n",
      "[[   0.8841   -0.1576   -0.4399 -109.2927]\n",
      " [   0.0675    0.9746   -0.2135  262.2687]\n",
      " [   0.4624    0.1591    0.8723  148.2321]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "c2 c3\n",
      "Reprojection Error Left:  1.5921\n",
      "Reprojection Error Right: 1.2066\n",
      "Transformation Matrix:\n",
      "[[  0.7488   0.2599  -0.6097 628.9282]\n",
      " [ -0.2567   0.9618   0.0947  15.5037]\n",
      " [  0.6111   0.0856   0.7869 502.3122]\n",
      " [  0.       0.       0.       1.    ]]\n",
      "c2 c4\n",
      "Not enough images \n",
      "\n",
      "c2 c5\n",
      "Reprojection Error Left:  1.2540\n",
      "Reprojection Error Right: 2.7230\n",
      "Transformation Matrix:\n",
      "[[   0.5214    0.1213   -0.8446  518.6375]\n",
      " [  -0.2279    0.9737   -0.0008 -261.1275]\n",
      " [   0.8223    0.1929    0.5353  524.3511]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "c2 c6\n",
      "Not enough images \n",
      "\n",
      "c3 c4\n",
      "Not enough images \n",
      "\n",
      "c3 c5\n",
      "Reprojection Error Left:  1.5342\n",
      "Reprojection Error Right: 1.1652\n",
      "Transformation Matrix:\n",
      "[[   0.9378   -0.0976   -0.3332   96.2663]\n",
      " [   0.0835    0.9949   -0.0564 -299.5696]\n",
      " [   0.337     0.0251    0.9412 -157.1114]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "c3 c6\n",
      "Not enough images \n",
      "\n",
      "c4 c5\n",
      "Not enough images \n",
      "\n",
      "c4 c6\n",
      "Reprojection Error Left:  1.0053\n",
      "Reprojection Error Right: 0.7703\n",
      "Transformation Matrix:\n",
      "[[   0.6799   -0.552     0.4827 -870.0134]\n",
      " [   0.578     0.8085    0.1104 -208.2455]\n",
      " [  -0.4512    0.204     0.8688  497.4683]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "c5 c6\n",
      "Not enough images \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cams = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6']\n",
    "for camL in cams:\n",
    "    for camR in cams[cams.index(camL)+1:]:\n",
    "        print(camL, camR)\n",
    "        stereopath = os.path.join(path_stereo, f'{camL}_{camR}')\n",
    "        Left_Paths = [os.path.join(stereopath, fname) for fname in list(os.listdir(stereopath)) if fname.split('_')[2] == camL]\n",
    "        Right_Paths = [os.path.join(stereopath, fname) for fname in list(os.listdir(stereopath)) if fname.split('_')[2] == camR]\n",
    "        \n",
    "        if len(Left_Paths) >= 1 and len(Right_Paths) >= 1:\n",
    "            Left_imgpoints, Left_Paths, Right_imgpoints, Right_Paths = cal.GenerateImagepoints(Left_Paths, Right_Paths, CHECKERBOARD)\n",
    "            if len(Left_imgpoints) >= 1 and len(Right_imgpoints) >= 1:\n",
    "\n",
    "                try:\n",
    "                    Ki = K[cams.index(camL)]\n",
    "                    Di = D[cams.index(camL)]\n",
    "                    Left_Params = cal.CalibrateCamera(Left_Paths, Left_imgpoints, K[cams.index(camL)], D[cams.index(camL)])\n",
    "\n",
    "                except IndexError:\n",
    "                    Left_Params = cal.CalibrateCamera(Left_Paths, Left_imgpoints)\n",
    "\n",
    "                try:\n",
    "                    Kj = K[cams.index(camR)]\n",
    "                    Dj = D[cams.index(camR)]\n",
    "                    Right_Params = cal.CalibrateCamera(Right_Paths, Right_imgpoints, Kj, Dj)\n",
    "                except IndexError:\n",
    "                    Right_Params = cal.CalibrateCamera(Right_Paths, Right_imgpoints)\n",
    "                Left_MeanError = np.mean(np.array(Left_Params['Errors']), axis=-1)\n",
    "                Right_MeanError = np.mean(np.array(Right_Params['Errors']), axis=-1)\n",
    "\n",
    "                Left_Params['Imgpoints'] = Left_imgpoints\n",
    "                Left_Params['MeanError'] = Left_MeanError\n",
    "\n",
    "                Right_Params['Imgpoints'] = Right_imgpoints\n",
    "                Right_Params['MeanError'] = Right_MeanError\n",
    "\n",
    "                print('Reprojection Error Left:  {:.4f}'.format(Left_MeanError))\n",
    "                print('Reprojection Error Right: {:.4f}'.format(Right_MeanError))                \n",
    "\n",
    "                Stereo_Params = cal.StereoCalibration(Left_Params, Right_Params, Left_imgpoints, Right_imgpoints, Left_Paths)\n",
    "                print('Transformation Matrix:')\n",
    "                print(Stereo_Params['Transformation'])\n",
    "\n",
    "                cal.SaveParameters(camL, camR, Stereo_Params, Left_Params, Right_Params)\n",
    "            else:\n",
    "                print('Not enough images', '\\n')\n",
    "        else:\n",
    "            print('Not enough images', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual selection of reference points on tabletop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_callback(event, x, y, flags, param):\n",
    "    \"\"\"Callback function to capture mouse clicks.\"\"\"\n",
    "    global clicked_points, cam\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        clicked_points.append((x, y))\n",
    "        point_num = len(clicked_points)\n",
    "\n",
    "        # Draw a small circle at the clicked point\n",
    "        cv2.circle(image, (x, y), 5, (0, 0, 255), -1)\n",
    "        # Add text indicating the point number\n",
    "        cv2.putText(image, f\"{point_num}\", (x, y), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        # Refresh the display\n",
    "        cv2.imshow(\"Image\", image)\n",
    "\n",
    "        # Stop after collecting 3 points\n",
    "        if len(clicked_points) == 3:\n",
    "            print(f\"Selected points for {cam}:\", clicked_points)\n",
    "            image_points[cam] = clicked_points.copy()\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "    return clicked_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected points for cam1: [(831, 618), (936, 711), (913, 576)]\n",
      "Selected points for cam4: [(694, 680), (827, 671), (679, 592)]\n",
      "Selected points for cam5: [(361, 538), (229, 601), (433, 606)]\n",
      "Selected points for cam6: [(478, 566), (552, 643), (552, 521)]\n"
     ]
    }
   ],
   "source": [
    "# Select 1 image per camera view where we see the reference points\n",
    "img1 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c1\\u102_c1g1_p3_1.png\"\n",
    "img4 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c4\\u102_c4g1_p3_338.png\"\n",
    "img5 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c5\\u102_c5g1_p3_399.png\"\n",
    "img6 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c6\\u102_c6g1_p3_404.png\"\n",
    "\n",
    "instructions = f\"Point 1 : origin 3 from L/4 from R \\n Point 2: x-axis -> 2 Middle \\n Point 3: y-axis 2 from R\"\n",
    "\n",
    "# Dictionary to store points for each image\n",
    "image_points = {}\n",
    "\n",
    "for img_path, cam in zip([img1, img4, img5, img6], ['cam1', 'cam4', 'cam5', 'cam6']):\n",
    "    image = cv2.imread(img_path)\n",
    "    clicked_points = []\n",
    "    # Display instructions on the image\n",
    "    cv2.putText(image, instructions, (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.setMouseCallback(\"Image\", mouse_callback)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# Save points to a JSON file\n",
    "with open(\"clicked_points_2.json\", \"w\") as file:\n",
    "    json.dump(image_points, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected points for cam2: [(692, 651), (574, 647), (688, 703)]\n",
      "Selected points for cam3: [(605, 657), (509, 714), (633, 690)]\n"
     ]
    }
   ],
   "source": [
    "# Select 1 image per camera view where we see the reference points\n",
    "img2 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c2\\u102_c2g1_p3_396.png\"\n",
    "img3 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c3\\u102_c3g1_p3_391.png\"\n",
    "\n",
    "instructions = f\"Point 1 : origin 3 from L/4 from R \\n Point 2: x-axis -> 2 Middle \\n Point 3: y-axis 2 from R\"\n",
    "\n",
    "# Dictionary to store points for each image\n",
    "image_points = {}\n",
    "\n",
    "for img_path, cam in zip([img2, img3], ['cam2', 'cam3']):\n",
    "    image = cv2.imread(img_path)\n",
    "    clicked_points = []\n",
    "    # Display instructions on the image\n",
    "    cv2.putText(image, instructions, (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.setMouseCallback(\"Image\", mouse_callback)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# Save points to a JSON file\n",
    "with open(\"saved_cobotique/clicked_points.json\", \"r\") as file:\n",
    "    image_points_base = json.load(file)\n",
    "\n",
    "image_points_base.update(image_points)\n",
    "\n",
    "with open(\"saved_cobotique/clicked_points_2.json\", \"w\") as file:\n",
    "    json.dump(image_points_base, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load points from JSON file\n",
    "with open(\"saved_cobotique/clicked_points_2.json\", \"r\") as file:\n",
    "    image_points = json.load(file)\n",
    "\n",
    "image_points_adjusted = image_points.copy()\n",
    "\n",
    "# Adjust points for cameras 2 and 3 (extend y-axis)\n",
    "for cam, (p0, p1, p2) in image_points_adjusted.items():\n",
    "    if cam in ['cam2', 'cam3']:\n",
    "        x0, y0 = p0\n",
    "        x2, y2 = p2\n",
    "        \n",
    "        dx, dy = x2 - x0, y2 - y0\n",
    "        p3 = (x2 + dx, y2 + dy) # Extend in the forward direction\n",
    "        \n",
    "        image_points_adjusted[cam][2] = p3\n",
    "\n",
    "with open(\"saved_cobotique/clicked_points_adjusted.json\", \"w\") as file:\n",
    "    json.dump(image_points_adjusted, file, indent=4)\n",
    "\n",
    "img1 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c1\\u102_c1g1_p3_1.png\"\n",
    "img2 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c2\\u102_c2g1_p3_396.png\"\n",
    "img3 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c3\\u102_c3g1_p3_391.png\"\n",
    "img4 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c4\\u102_c4g1_p3_338.png\"\n",
    "img5 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c5\\u102_c5g1_p3_399.png\"\n",
    "img6 = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed\\c6\\u102_c6g1_p3_404.png\"\n",
    "\n",
    "img_paths = [img1, img2, img3, img4, img5, img6]\n",
    "cams = ['cam1', 'cam2', 'cam3', 'cam4', 'cam5', 'cam6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize selected points (for validation purpose)\n",
    "\n",
    "with open(\"saved_cobotique/clicked_points_adjusted.json\", \"r\") as file:\n",
    "    image_points = json.load(file)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(16,12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(6):\n",
    "    c1 = int(cams[i][-1]) - 1\n",
    "        \n",
    "    pts1_im = np.array(image_points[cams[i]], dtype=np.float32)\n",
    "    img_path1 = img_paths[i]\n",
    "    img = cv2.imread(img_path1)\n",
    "\n",
    "    img = draw_circles(img, pts1_im, None, False)\n",
    "    axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f'Cam {i+1}', fontsize=8)\n",
    "\n",
    "fig.suptitle(\"Original 2D Points (Blue)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_c4 = np.load('saved_cobotique/c1_c4_parameters.npz')['Transformation']\n",
    "c1_c5 = np.load('saved_cobotique/c1_c5_parameters.npz')['Transformation']\n",
    "c1_c6 = np.load('saved_cobotique/c1_c6_parameters.npz')['Transformation']\n",
    "c2_c3 = np.load('saved_cobotique/c2_c3_parameters.npz')['Transformation']\n",
    "c2_c5 = np.load('saved_cobotique/c2_c5_parameters.npz')['Transformation']\n",
    "c3_c5 = np.load('saved_cobotique/c3_c5_parameters.npz')['Transformation']\n",
    "c4_c6 = np.load('saved_cobotique/c4_c6_parameters.npz')['Transformation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_name(var, scope=globals()):\n",
    "    return [name for name, value in scope.items() if value is var][0]\n",
    "\n",
    "def compare_transfo(T12, T23, T13):\n",
    "    print(f'Original {var_name(T13)}')\n",
    "    print(T13)\n",
    "    T13_calc = T12 @ T23\n",
    "    print(f'Calculated {var_name(T13)}')\n",
    "    print(T13_calc)\n",
    "    print('Calculated I')\n",
    "    print(np.linalg.inv(T13_calc) @ T13, '\\n')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original c4_c6\n",
      "[[   0.6799   -0.552     0.4827 -870.0134]\n",
      " [   0.578     0.8085    0.1104 -208.2455]\n",
      " [  -0.4512    0.204     0.8688  497.4683]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "Calculated c4_c6\n",
      "[[   0.7677   -0.3165    0.5572 -546.4253]\n",
      " [   0.5254    0.8087   -0.2644  -55.3691]\n",
      " [  -0.3669    0.4958    0.7871  932.795 ]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "Calculated I\n",
      "[[   0.9912   -0.0737    0.1098 -168.9978]\n",
      " [   0.0285    0.9297    0.3672 -237.029 ]\n",
      " [  -0.1291   -0.3608    0.9236 -482.5419]\n",
      " [   0.        0.        0.        1.    ]] \n",
      "\n",
      "Original c3_c5\n",
      "[[   0.9378   -0.0976   -0.3332   96.2663]\n",
      " [   0.0835    0.9949   -0.0564 -299.5696]\n",
      " [   0.337     0.0251    0.9412 -157.1114]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "Calculated c3_c5\n",
      "[[   0.9514   -0.0412   -0.3051    1.8994]\n",
      " [  -0.0133    0.9846   -0.1744 -292.8513]\n",
      " [   0.3076    0.17      0.9362   58.388 ]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "Calculated I\n",
      "[[   0.9948   -0.0983   -0.0267   23.5894]\n",
      " [   0.1008    0.9879    0.1182  -47.145 ]\n",
      " [   0.0148   -0.1203    0.9926 -229.3712]\n",
      " [   0.        0.        0.        1.    ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_transfo(np.linalg.inv(c1_c4), c1_c6, c4_c6) # OK\n",
    "\n",
    "compare_transfo(np.linalg.inv(c2_c3), c2_c5, c3_c5) # OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimizer pour paramètres intrinsèques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "par image et par caméra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m init_params \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [r[\u001b[38;5;241m0\u001b[39m], r[\u001b[38;5;241m1\u001b[39m], r[\u001b[38;5;241m2\u001b[39m]]\n\u001b[0;32m     23\u001b[0m init_params \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;241m0\u001b[39m], t[\u001b[38;5;241m1\u001b[39m], t[\u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m---> 25\u001b[0m init_params \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to NumPy array\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, init_params)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Define Optimizer hyperparameters\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration\\intrinsics\\c1\"\n",
    "\n",
    "objpoints = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objpoints[:, :2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "objpoints[:, :2] = objpoints[:, 0:2] * SQUARE_SIZE\n",
    "\n",
    "im_name = os.path.join(path, os.listdir(path)[30])\n",
    "img = cv2.imread(os.path.join(path, im_name))\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "_, imgpoints = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "imgpoints = imgpoints.squeeze()\n",
    "imgpoints = imgpoints.astype(np.float32)\n",
    "\n",
    "_, r, t = cv2.solvePnP(objpoints, imgpoints, K[0], D[0])\n",
    "r = r.flatten()\n",
    "t = t.flatten()\n",
    "\n",
    "# Define the initial parameter values\n",
    "params_c1 = K[0]\n",
    "init_params = [params_c1[0,0], params_c1[1,1], params_c1[0,2], params_c1[1,2]]\n",
    "init_params += list(D[0])\n",
    "init_params += [r[0], r[1], r[2]]\n",
    "init_params += [t[0], t[1], t[2]]\n",
    "\n",
    "init_params = np.array(init_params, dtype=np.float32)  # Convert to NumPy array\n",
    "print(\"Initial Parameters:\", init_params)\n",
    "\n",
    "# Define Optimizer hyperparameters\n",
    "n_particles = 50  # Number of particles\n",
    "\n",
    "init_pos = np.tile(init_params, (n_particles, 1))  # Shape: (30, 15)\n",
    "print(\"Initial Position Shape:\", init_pos.shape)  # Should be (30, 15)\n",
    "\n",
    "param_bounds = ([500, 500, 600, 300, -0.1, -0.1, -0.01, -0.01, -0.1, -np.pi, -np.pi, -np.pi, -1000, -1000, -1000],  # Lower bounds\n",
    "                [700, 700, 700, 400, 0.1, 0.1, 0.01, 0.01, 0.1, np.pi, np.pi, np.pi, 1000, 1000, 2000])          # Upper bounds\n",
    "param_bounds = np.array(param_bounds, dtype=np.float32).reshape((2,15))\n",
    "print(param_bounds)\n",
    "print('Param bounds Shape:', param_bounds.shape)\n",
    "\n",
    "options = {'c1': 1.5, 'c2': 0.3, 'w': 0.5}  # Cognitive, social, and inertia weights\n",
    "\n",
    "# Define projection Model\n",
    "def project_points(params, obj_pts):\n",
    "    \"\"\"\n",
    "    Projects 3D points to 2D using intrinsic parameters.\n",
    "    params = [fx, fy, cx, cy, k1, k2, p1, p2, k3] (9 parameters)\n",
    "    \"\"\"\n",
    "    fx, fy, cx, cy, k1, k2, p1, p2, k3, r1, r2, r3, t1, t2, t3 = params\n",
    "    \n",
    "    camera_matrix = np.array([[fx, 0, cx],\n",
    "                              [0, fy, cy],\n",
    "                              [0,  0,  1] ], dtype=np.float32)\n",
    "    dist_coeffs = np.array([k1, k2, p1, p2, k3])\n",
    "\n",
    "    rvec = np.array([r1, r2, r3])\n",
    "    tvec = np.array([t1, t2, t3])\n",
    "    \n",
    "    # Project points\n",
    "    projected_pts, _ = cv2.projectPoints(obj_pts, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    return projected_pts.squeeze()\n",
    "\n",
    "# Define cost function\n",
    "def RMSE(params):\n",
    "    errors = np.zeros(n_particles)  # Array to store errors\n",
    "\n",
    "    for i in range(n_particles):  \n",
    "        imgp_proj = project_points(params[i], objpoints)  # Project points for this particle\n",
    "        \n",
    "        squared_diff = (imgpoints - imgp_proj) ** 2\n",
    "        mse = np.mean(np.sum(squared_diff, axis=1))\n",
    "        rmse = np.sqrt(mse)\n",
    "        errors[i] = np.mean(rmse)  # Store mean RMSE for this particle\n",
    "    \n",
    "    return errors  # Return array of errors (one per particle)\n",
    "\n",
    "# Run PSO to optimize calibration parameters\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=n_particles, dimensions=15, options=options, bounds=param_bounds, init_pos=init_pos)\n",
    "best_error, best_params = optimizer.optimize(RMSE, iters=500)\n",
    "\n",
    "plot_cost_history(cost_history=optimizer.cost_history)\n",
    "plt.show()\n",
    "\n",
    "# Extract optimized parameters\n",
    "fx, fy, cx, cy, k1, k2, p1, p2, k3, r1, r2, r3, t1, t2, t3 = best_params\n",
    "\n",
    "# Create final camera matrix\n",
    "optimized_camera_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "optimized_dist_coeffs = np.array([k1, k2, p1, p2, k3])\n",
    "optimized_rvec = np.array([r1, r2, r3])\n",
    "optimized_tvec = np.array([t1, t2, t3])\n",
    "\n",
    "print(\"Optimized Camera Matrix:\\n\", optimized_camera_matrix)\n",
    "print(\"Optimized Distortion Coefficients:\\n\", optimized_dist_coeffs)\n",
    "print(\"Optimized Rotation Vector:\\n\", optimized_rvec)\n",
    "print(\"Optimized Translation Vector:\\n\", optimized_tvec)\n",
    "print(f\"Best Reprojection Error: {best_error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour toutes les images de toutes les caméras en même temps, (r,t) avec SolvePnP pour chaque image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "num_cameras = 6\n",
    "num_params_per_cam = 9\n",
    "total_params = num_cameras * num_params_per_cam\n",
    "n_particles = 50  # Number of particles\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.5}  # PSO Hyperparameters\n",
    "\n",
    "# Paths to calibration images for each camera\n",
    "base_path = r\"C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration\\intrinsics_refine\"\n",
    "camera_paths = [os.path.join(base_path, f'c{i+1}') for i in range(num_cameras)]\n",
    "\n",
    "# Generate 3D object points (same for all images)\n",
    "objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2) * SQUARE_SIZE\n",
    "\n",
    "# Initial parameters for each camera\n",
    "K_fab = [[[644, 0, 656], [0, 643, 358], [0,0,1]],\n",
    "         [[638, 0, 645], [0, 637, 363], [0,0,1]],\n",
    "         [[645, 0, 645], [0, 643, 362], [0,0,1]],\n",
    "         [[644, 0, 637], [0, 643, 358], [0,0,1]],\n",
    "         [[642, 0, 650], [0, 641, 357], [0,0,1]],\n",
    "         [[644, 0, 650], [0, 642, 362], [0,0,1]]]\n",
    "K_fab = np.array(K_fab, dtype=np.float32)\n",
    "\n",
    "K_calc = np.load('Intrinsics_K.npz')['arr_0']\n",
    "D_calc = np.load('Intrinsics_D.npz')['arr_0']\n",
    "\n",
    "K = K_fab       # Choose between theorical or calculated params K_fab / K_calc\n",
    "D = [np.zeros(5, dtype=np.float32) for _ in range(num_cameras)]  # Distortion Coeffs\n",
    "\n",
    "# Store object points and image points for all cameras\n",
    "objpoints_list = []  # 3D points (same for all cameras)\n",
    "imgpoints_list = [[] for _ in range(num_cameras)]  # 2D points per camera\n",
    "extrinsics_list = [[] for _ in range(num_cameras)] \n",
    "\n",
    "for cam_idx, cam_path in enumerate(camera_paths):\n",
    "    img_files = os.listdir(cam_path)\n",
    "    for img_name in img_files:\n",
    "        img_path = os.path.join(cam_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "        if ret:\n",
    "            corners = corners.squeeze().astype(np.float32)\n",
    "            imgpoints_list[cam_idx].append(corners)\n",
    "            objpoints_list.append(objp)\n",
    "\n",
    "init_params = []\n",
    "for cam_idx in range(num_cameras):\n",
    "    cam_init = [K[cam_idx,0, 0], K[cam_idx,1, 1], K[cam_idx,0, 2], K[cam_idx,1, 2]]\n",
    "    cam_init += list(D[cam_idx])\n",
    "    init_params.extend(cam_init)\n",
    "\n",
    "init_params = np.array(init_params, dtype=np.float32)\n",
    "\n",
    "# Define parameter bounds\n",
    "lower_bounds = [500, 500, 600, 300, -0.1, -0.1, -0.01, -0.01, -0.1]\n",
    "upper_bounds = [700, 700, 700, 400, 0.1, 0.1, 0.01, 0.01, 0.1]\n",
    "\n",
    "param_bounds = (np.tile(lower_bounds, num_cameras), np.tile(upper_bounds, num_cameras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 09:42:44,303 - pyswarms.single.global_best - INFO - Optimize for 20 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.5}\n",
      "pyswarms.single.global_best:  10%|█         |2/20, best_cost=1.46C:\\Users\\LEA\\AppData\\Local\\Temp\\ipykernel_76732\\2601850050.py:31: RuntimeWarning: overflow encountered in square\n",
      "  squared_diff = (img_pts - projected_pts) ** 2\n",
      "pyswarms.single.global_best: 100%|██████████|20/20, best_cost=1.34\n",
      "2025-02-28 09:44:36,865 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.3413528294807702, best pos: [629.0066 692.2739 609.1485 360.4797   0.0982  -0.0352   0.0028  -0.0043\n",
      "  -0.0398 628.8125 615.7793 620.3899 378.6241  -0.0332  -0.0843   0.0002\n",
      "  -0.0009  -0.0363 626.9632 587.0663 642.742  354.7231  -0.0028  -0.0474\n",
      "  -0.0046   0.0006   0.024  578.8816 560.0724 619.7809 314.7627  -0.0416\n",
      "   0.0479   0.0067   0.0004  -0.012  658.3184 525.7467 655.8684 359.267\n",
      "   0.0647   0.0153   0.0063   0.0053   0.0202 512.6711 629.2437 674.0313\n",
      " 306.5824  -0.0234   0.0505  -0.0092   0.007    0.0099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 1 Optimized Parameters:\n",
      "Optimized Camera Matrix:\n",
      " [[629.0066   0.     609.1485]\n",
      " [  0.     692.2739 360.4797]\n",
      " [  0.       0.       1.    ]]\n",
      "Optimized Distortion Coefficients:\n",
      " [ 0.0982 -0.0352  0.0028 -0.0043 -0.0398]\n",
      "\n",
      "\n",
      "Camera 2 Optimized Parameters:\n",
      "Optimized Camera Matrix:\n",
      " [[628.8125   0.     620.3899]\n",
      " [  0.     615.7793 378.6241]\n",
      " [  0.       0.       1.    ]]\n",
      "Optimized Distortion Coefficients:\n",
      " [-0.0332 -0.0843  0.0002 -0.0009 -0.0363]\n",
      "\n",
      "\n",
      "Camera 3 Optimized Parameters:\n",
      "Optimized Camera Matrix:\n",
      " [[626.9632   0.     642.742 ]\n",
      " [  0.     587.0663 354.7231]\n",
      " [  0.       0.       1.    ]]\n",
      "Optimized Distortion Coefficients:\n",
      " [-0.0028 -0.0474 -0.0046  0.0006  0.024 ]\n",
      "\n",
      "\n",
      "Camera 4 Optimized Parameters:\n",
      "Optimized Camera Matrix:\n",
      " [[578.8816   0.     619.7809]\n",
      " [  0.     560.0724 314.7627]\n",
      " [  0.       0.       1.    ]]\n",
      "Optimized Distortion Coefficients:\n",
      " [-0.0416  0.0479  0.0067  0.0004 -0.012 ]\n",
      "\n",
      "\n",
      "Camera 5 Optimized Parameters:\n",
      "Optimized Camera Matrix:\n",
      " [[658.3184   0.     655.8684]\n",
      " [  0.     525.7467 359.267 ]\n",
      " [  0.       0.       1.    ]]\n",
      "Optimized Distortion Coefficients:\n",
      " [0.0647 0.0153 0.0063 0.0053 0.0202]\n",
      "\n",
      "\n",
      "Camera 6 Optimized Parameters:\n",
      "Optimized Camera Matrix:\n",
      " [[512.6711   0.     674.0313]\n",
      " [  0.     629.2437 306.5824]\n",
      " [  0.       0.       1.    ]]\n",
      "Optimized Distortion Coefficients:\n",
      " [-0.0234  0.0505 -0.0092  0.007   0.0099]\n",
      "\n",
      "\n",
      "Best Reprojection Error: 1.3413528294807702\n"
     ]
    }
   ],
   "source": [
    "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.5}  # PSO Hyperparameters\n",
    "\n",
    "# Projection function\n",
    "def project_points(camera_matrix, dist_coeffs, r, t, obj_pts):\n",
    "    projected_pts, _ = cv2.projectPoints(obj_pts, r, t, camera_matrix, dist_coeffs)\n",
    "    return projected_pts.squeeze()\n",
    "\n",
    "# Define cost function\n",
    "def RMSE(params):\n",
    "    errors = np.zeros(n_particles)\n",
    "    num_images = len(objpoints_list)  # Total images used for calibration\n",
    "    \n",
    "    for i in range(n_particles):\n",
    "        total_error = 0\n",
    "        for cam_idx in range(num_cameras):\n",
    "            cam_params = params[i][cam_idx * num_params_per_cam : (cam_idx + 1) * num_params_per_cam]\n",
    "            fx, fy, cx, cy, k1, k2, p1, p2, k3 = cam_params\n",
    "            camera_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0,  0,  1]], dtype=np.float64)\n",
    "            dist_coeffs = np.array([k1, k2, p1, p2, k3], dtype=np.float64)\n",
    "\n",
    "            for (obj_pts, img_pts) in zip(objpoints_list, imgpoints_list[cam_idx]):\n",
    "                _, r, t = cv2.solvePnP(obj_pts, img_pts, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_EPNP)\n",
    "\n",
    "                projected_pts = project_points(camera_matrix, dist_coeffs, r, t, obj_pts)\n",
    "\n",
    "                squared_diff = (img_pts - projected_pts) ** 2\n",
    "                mse = np.mean(np.sum(squared_diff, axis=1))\n",
    "                rmse = np.sqrt(mse)\n",
    "                total_error += rmse\n",
    "        \n",
    "        errors[i] = total_error / (num_cameras * num_images)\n",
    "    \n",
    "    return errors[i]\n",
    "\n",
    "# Run PSO to optimize calibration parameters\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=n_particles, dimensions=total_params, options=options, bounds=param_bounds)\n",
    "best_error, best_params = optimizer.optimize(RMSE, iters=20)\n",
    "\n",
    "# Extract optimized parameters for each camera\n",
    "optimized_params = np.split(best_params, num_cameras)\n",
    "for cam_idx in range(num_cameras):\n",
    "    fx, fy, cx, cy, k1, k2, p1, p2, k3 = optimized_params[cam_idx]\n",
    "    optimized_camera_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "    optimized_dist_coeffs = np.array([k1, k2, p1, p2, k3])\n",
    "    print(f\"Camera {cam_idx+1} Optimized Parameters:\")\n",
    "    print(\"Optimized Camera Matrix:\\n\", optimized_camera_matrix)\n",
    "    print(\"Optimized Distortion Coefficients:\\n\", optimized_dist_coeffs)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(f\"Best Reprojection Error: {best_error}\")\n",
    "\n",
    "plot_cost_history(cost_history=optimizer.cost_history)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D reprojection error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to project 3D points to 2D\n",
    "def project_points(points_3d, projMat, K, D):\n",
    "    rvec, _ = cv2.Rodrigues(projMat[0:3,0:3])\n",
    "    projected_2d, _ = cv2.projectPoints(points_3d, rvec, projMat[0:3,3], K, D)\n",
    "    return projected_2d.squeeze()\n",
    "\n",
    "# Compute RMSE\n",
    "def compute_rmse(original_pts, points_3d, projMat, K, D):\n",
    "    projected_pts = project_points(points_3d, projMat, K, D)\n",
    "    error = np.linalg.norm(original_pts - projected_pts, axis=1)  # Euclidean distance per point\n",
    "    rmse = np.sqrt(np.mean(error**2))  # Compute RMSE\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo initial extrinsic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'C:\\\\Users\\\\LEA\\\\Desktop\\\\Poly\\\\Trampo\\\\data_cobotique\\\\calibration_0703\\\\stereo_confirmed\\\\cam1_cam2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m name1 \u001b[38;5;241m=\u001b[39m user \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m cam1 \u001b[38;5;241m+\u001b[39m cali1[\u001b[38;5;241m0\u001b[39m,i]\n\u001b[0;32m     19\u001b[0m name2 \u001b[38;5;241m=\u001b[39m user \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m cam2 \u001b[38;5;241m+\u001b[39m cali2[\u001b[38;5;241m0\u001b[39m,j]\n\u001b[1;32m---> 21\u001b[0m im1In \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcam1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_stereo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m im2In \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcam2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(path_stereo))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im1In \u001b[38;5;129;01mand\u001b[39;00m im2In:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'C:\\\\Users\\\\LEA\\\\Desktop\\\\Poly\\\\Trampo\\\\data_cobotique\\\\calibration_0703\\\\stereo_confirmed\\\\cam1_cam2'"
     ]
    }
   ],
   "source": [
    "# Create array of all stereo images with 'im_name, img_pts, cam_ timestamp'\n",
    "stereo_images = {'Name':[], 'Camera':[], 'Img_pts':[], 'Time':[]}\n",
    "\n",
    "for user in ['u101', 'u102']:\n",
    "\n",
    "    for cam1 in cams:\n",
    "        cali1 = cal.retrieve_cali_info(path, user, cam1[-1])\n",
    "        for cam2 in cams[cams.index(cam1)+1:]:\n",
    "            cali2 = cal.retrieve_cali_info(path, user, cam2[-1])\n",
    "            path_stereo = os.path.join(path_stereo, f'{cam1}_{cam2}')\n",
    "\n",
    "            for i,t1 in enumerate(cali1[1,:]):\n",
    "                t1 = float(t1)\n",
    "                for j,t2 in enumerate(cali2[1,:]):\n",
    "                    t2 = float(t2)\n",
    "                    if abs(t1-t2) < time_threshold:\n",
    "\n",
    "                        name1 = user + '_' + cam1 + cali1[0,i]\n",
    "                        name2 = user + '_' + cam2 + cali2[0,j]\n",
    "                        \n",
    "                        im1In = f'{i}_{j}_{cam1}_{name1}' in list(os.listdir(path_stereo))\n",
    "                        im2In = f'{i}_{j}_{cam2}_{name2}' in list(os.listdir(path_stereo))\n",
    "                                \n",
    "                        if im1In and im2In:\n",
    "                            Lret, Limg, Limg_pts = cal.findCorners(os.path.join(path_stereo, f'{i}_{j}_{cam1}_{name1}'))\n",
    "                            Rret, Rimg, Rimg_pts = cal.findCorners(os.path.join(path_stereo, f'{i}_{j}_{cam2}_{name2}'))\n",
    "\n",
    "                            if Lret and Rret:\n",
    "                                stereo_images['Name'].append(name1)\n",
    "                                stereo_images['Camera'].append(int(cam1[-1]))\n",
    "                                stereo_images['Img_pts'].append(Limg_pts)\n",
    "                                stereo_images['Time'].append(t1)\n",
    "\n",
    "                                stereo_images['Name'].append(name2)\n",
    "                                stereo_images['Camera'].append(int(cam2[-1]))\n",
    "                                stereo_images['Img_pts'].append(Rimg_pts)\n",
    "                                stereo_images['Time'].append(t2)\n",
    "\n",
    "with open('stereo_data_final.pkl', 'wb') as f:\n",
    "    pickle.dump(stereo_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_cobotique/stereo_data_final.pkl', 'rb') as f:\n",
    "    stereo_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[   -0.5464    -0.5674     0.6161 -2024.6351]\n",
      " [    0.043      0.7156     0.6972 -1010.4567]\n",
      " [   -0.8364     0.4074    -0.3665  1777.0763]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "[[    0.1142    -0.5128     0.8509 -1867.7053]\n",
      " [    0.2121     0.8493     0.4834  -499.4606]\n",
      " [   -0.9705     0.1253     0.2058  1207.9708]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "[[   0.4834    0.4534   -0.7488  878.467 ]\n",
      " [  -0.3757    0.8801    0.2903 -165.104 ]\n",
      " [   0.7907    0.1409    0.5958   32.3176]\n",
      " [   0.        0.        0.        1.    ]]\n",
      "[[    0.351     -0.4999     0.7917 -1836.7874]\n",
      " [    0.4327     0.8365     0.3363  -809.4149]\n",
      " [   -0.8304     0.2245     0.5099  1044.6748]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "[[   0.8841   -0.1576   -0.4399 -109.2927]\n",
      " [   0.0675    0.9746   -0.2135  262.2687]\n",
      " [   0.4624    0.1591    0.8723  148.2321]\n",
      " [   0.        0.        0.        1.    ]]\n"
     ]
    }
   ],
   "source": [
    "Tcam1 = np.eye((4))\n",
    "Tcam6 = c1_c6\n",
    "Tcam4 = c1_c4\n",
    "Tcam5 = c1_c5\n",
    "Tcam3 = Tcam5 @ np.linalg.inv(c3_c5)\n",
    "Tcam2 = Tcam5 @ np.linalg.inv(c2_c5)\n",
    "\n",
    "projMat = [Tcam1, Tcam2, Tcam3, Tcam4, Tcam5, Tcam6]\n",
    "\n",
    "for mat in projMat:\n",
    "    print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_projection(img_path, pts_2d_original, pts_3d, projMat, K, D):\n",
    "    \"\"\"\n",
    "    Visualize original 2D points and projected 3D points on an image.\n",
    "\n",
    "    Parameters:\n",
    "    - img_path: Path to the image.\n",
    "    - pts_2d_original: Original 2D keypoints (Nx2).\n",
    "    - pts_3d: Triangulated 3D points (Nx3).\n",
    "    - projMat: Projection matrix (3x4).\n",
    "    - K: Camera intrinsic matrix (3x3).\n",
    "    - D: Distortion coefficients (1x5 or 1x4).\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for i in range(len(img_path)):\n",
    "\n",
    "        # Load the image\n",
    "        img = cv2.imread(img_path[i])\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path[i]}\")\n",
    "\n",
    "        # Project 3D points onto the image plane\n",
    "        pts_2d_projected, _ = cv2.projectPoints(pts_3d[i], projMat[i][0:3,0:3], projMat[i][0:3,3], K[i], D[i])\n",
    "\n",
    "        # Reshape projected points\n",
    "        pts_2d_projected = pts_2d_projected.squeeze()\n",
    "\n",
    "        # Draw the original and projected points\n",
    "        for j in range(len(pts_2d_original[i])):\n",
    "            x_orig, y_orig = map(int, pts_2d_original[i][j])  # Original 2D point\n",
    "            x_proj, y_proj = map(int, pts_2d_projected[j])  # Reprojected 3D point\n",
    "\n",
    "            # Draw original points in BLUE\n",
    "            cv2.circle(img, (x_orig, y_orig), 4, (255, 0, 0), -1)\n",
    "\n",
    "            # Draw reprojected points in GREEN\n",
    "            cv2.circle(img, (x_proj, y_proj), 4, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw line between them (error visualization)\n",
    "            cv2.line(img, (x_orig, y_orig), (x_proj, y_proj), (0, 255, 255), 1)\n",
    "\n",
    "            fig = plt.subplot(1,2,i+1)\n",
    "            fig.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.title(\"Original 2D Points (Blue) vs. Projected 3D Points (Green)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO for extrinsic parameters (with Bundle adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(60, 30)\n",
      "(30,)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "num_cameras = 5\n",
    "num_params_per_cam = 6\n",
    "total_params = num_cameras * num_params_per_cam\n",
    "n_particles = 60  # Number of particles\n",
    "options = {'c1': 1.5, 'c2': 1.5, 'w': 0.4} #{'c1': 2.05, 'c2': 2.05, 'w': 0.729} # PSO Hyperparameters\n",
    "\n",
    "projMat = np.load('saved_cobotique/Extrinsics_optimized_15.npz')['arr_0']\n",
    "\n",
    "init_params = []\n",
    "for mat in projMat:\n",
    "    rvec, _ = cv2.Rodrigues(mat[0:3,0:3])\n",
    "    rvec = rvec.squeeze()\n",
    "    params = [rvec[0], rvec[1], rvec[2], mat[0,3], mat[1,3], mat[2,3]]\n",
    "    init_params.extend(params)\n",
    "\n",
    "init_params = np.array(init_params, dtype=np.float64)\n",
    "init_pos = np.tile(init_params, (n_particles,1))\n",
    "print(init_params.shape)\n",
    "print(init_pos.shape)\n",
    "\n",
    "# Define parameter bounds\n",
    "lower_bounds = [-2*np.pi, -2*np.pi, -2*np.pi, -3000, -3000, -3000]\n",
    "upper_bounds = [2*np.pi, 2*np.pi, 2*np.pi, 3000, 3000, 3000]\n",
    "\n",
    "param_bounds = (np.tile(lower_bounds, num_cameras), np.tile(upper_bounds, num_cameras))\n",
    "print(param_bounds[0].shape)\n",
    "\n",
    "print(np.all(param_bounds[0] <= init_pos[0]))\n",
    "print(np.all(init_pos[0] <= param_bounds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(params):\n",
    "    errors = np.empty((n_particles,))\n",
    "    params = np.array(params)\n",
    "\n",
    "    for n in range(n_particles):\n",
    "        \n",
    "        projMat = np.empty((num_cameras+1, 3, 4))\n",
    "        projMat[0] = np.hstack((np.eye((3)), np.zeros((3,1))))\n",
    "\n",
    "        for cam_idx in range(num_cameras):\n",
    "            cam_params = params[n][cam_idx * num_params_per_cam : (cam_idx + 1) * num_params_per_cam]\n",
    "            r1, r2, r3, t1, t2, t3 = cam_params\n",
    "            rvec = np.array([r1, r2, r3])\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            t = np.array([t1, t2, t3]).reshape((3,1))\n",
    "            projMat[cam_idx+1] = np.hstack((R, t))  #[cam_idx+1]\n",
    "\n",
    "        RMSE = {c:[] for c in range(6)}\n",
    "        # Loop on stereo images checkberboard points\n",
    "        for i in range(0, len(stereo_data['Camera']) - 1, 2):\n",
    "            j = i+1 # stereo image is the next one\n",
    "\n",
    "            pts1_im = stereo_data['Img_pts'][i].squeeze()\n",
    "            pts2_im = stereo_data['Img_pts'][j].squeeze()\n",
    "\n",
    "            c1 = int(stereo_data['Camera'][i]) - 1\n",
    "            c2 = int(stereo_data['Camera'][j]) - 1\n",
    "\n",
    "            \"\"\" t1 = float(stereo_data['Time'][i])\n",
    "            t2 = float(stereo_data['Time'][j])\n",
    "            assert abs(t1-t2) < time_threshold, f'Images are not matching: {t1:.4f} and {t2:.4f}' \"\"\"\n",
    "\n",
    "            undist_pts1 = cv2.undistortPoints(pts1_im, K[c1], D[c1]).reshape(-1, 2).T  # Shape (2, N)\n",
    "            undist_pts2 = cv2.undistortPoints(pts2_im, K[c2], D[c2]).reshape(-1, 2).T  # Shape (2, N)\n",
    "\n",
    "            # Perform triangulation\n",
    "            pts_4d = cv2.triangulatePoints(projMat[c1], projMat[c2], undist_pts1, undist_pts2)\n",
    "            points_3d = pts_4d[:3, :] / pts_4d[3, :]  # Shape (3, N)\n",
    "            points_3d = points_3d.T  # Shape (N, 3)\n",
    "\n",
    "            # Compute RMSE for both cameras\n",
    "            rmse1 = compute_rmse(pts1_im, points_3d, projMat[c1], K[c1], D[c1])\n",
    "            rmse2 = compute_rmse(pts2_im, points_3d, projMat[c2], K[c2], D[c2])\n",
    "\n",
    "            RMSE[c1].append(rmse1)\n",
    "            RMSE[c2].append(rmse2)\n",
    "\n",
    "        # Loop on tabletop reference points\n",
    "        RMSE_tt = []\n",
    "        for i in range(4):\n",
    "            c1 = int(cams[i][-1]) - 1\n",
    "\n",
    "            pts1_im = np.array(image_points[cams[i]], dtype=np.float32)\n",
    "            undist_pts1 = cv2.undistortPoints(pts1_im, K[c1], D[c1]).reshape(-1, 2).T  # Shape (2, N)\n",
    "\n",
    "            for j in range(i+1,4):\n",
    "                c2 = int(cams[j][-1]) - 1\n",
    "\n",
    "                pts2_im = np.array(image_points[cams[j]], dtype=np.float32)\n",
    "                undist_pts2 = cv2.undistortPoints(pts2_im, K[c2], D[c2]).reshape(-1, 2).T  # Shape (2, N)\n",
    "\n",
    "                # Perform triangulation\n",
    "                pts_4d = cv2.triangulatePoints(projMat[c1], projMat[c2], undist_pts1, undist_pts2)\n",
    "                points_3d = pts_4d[:3, :] / pts_4d[3, :]  # Shape (3, N)\n",
    "                points_3d = points_3d.T  # Shape (N, 3)\n",
    "\n",
    "                err_x = (304.8 - np.linalg.norm(points_3d[0] - points_3d[1]))**2\n",
    "                err_y = (304.8 - np.linalg.norm(points_3d[0] - points_3d[2]))**2\n",
    "                err_d = (431.0523 - np.linalg.norm(points_3d[1] - points_3d[2]))**2\n",
    "\n",
    "                cost_dist = np.sqrt(np.mean([err_x, err_y, err_d]))\n",
    "\n",
    "                rmse1_tt = compute_rmse(pts1_im, points_3d, projMat[c1], K[c1], D[c1])\n",
    "                rmse2_tt = compute_rmse(pts2_im, points_3d, projMat[c2], K[c2], D[c2])\n",
    "\n",
    "                RMSE_tt.append(rmse1_tt)\n",
    "                RMSE_tt.append(rmse2_tt)\n",
    "\n",
    "        # Per-camera mean RMSE\n",
    "        rmse_mean = []\n",
    "        for _, rmse in RMSE.items():\n",
    "            rmse_mean.append(np.mean(rmse))\n",
    "        \n",
    "        # global mean\n",
    "        e = np.mean(rmse_mean) + np.mean(RMSE_tt) + cost_dist #+ np.max(RMSE)  + np.max(RMSE_tt)\n",
    "        errors[n] = e   # OPTIONAL: add max error to cost function\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 10:59:21,610 - pyswarms.single.global_best - INFO - Optimize for 500 iters with {'c1': 1.5, 'c2': 1.5, 'w': 0.4}\n",
      "pyswarms.single.global_best:   0%|          |0/500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████|500/500, best_cost=8.01\n",
      "2025-03-25 11:07:22,385 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 8.014896389324036, best pos: [   -0.0255     2.0312     0.7895  -632.7989  -657.2509  2344.2767\n",
      "     0.0184     1.3927     0.5038 -1435.8987  -220.5955  1939.3818\n",
      "    -0.1865    -1.0159    -0.437    806.1666  -220.7843   169.7508\n",
      "    -0.0661     1.0505     0.5993 -1873.4689  -752.8458  1182.9457\n",
      "     0.1841    -0.4682     0.1174  -112.1726   255.2391   141.9347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Reprojection Error: 8.014896389324036 pixels\n"
     ]
    }
   ],
   "source": [
    "# Run PSO to optimize calibration parameters\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=n_particles, dimensions=total_params, options=options, bounds=param_bounds, init_pos=init_pos)\n",
    "best_error, best_params = optimizer.optimize(fun, iters = 500)\n",
    "print(f\"Best Reprojection Error: {best_error} pixels\")\n",
    "\n",
    "# Extract optimized parameters for each camera\n",
    "optimized_params = np.split(best_params, num_cameras)\n",
    "\n",
    "plot_cost_history(cost_history=optimizer.cost_history)\n",
    "plt.savefig('saved_cobotique/Figure_1_pso_cost_13.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 1 Optimized Camera Matrix:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Camera 2 Optimized Camera Matrix:\n",
      " [[  -0.5715   -0.3143    0.758  -632.7989]\n",
      " [   0.2801    0.7935    0.5402 -657.2509]\n",
      " [  -0.7713    0.521    -0.3655 2344.2767]]\n",
      "Camera 3 Optimized Camera Matrix:\n",
      " [[    0.0897    -0.3282     0.9403 -1435.8987]\n",
      " [    0.3494     0.8945     0.2789  -220.5955]\n",
      " [   -0.9327     0.3036     0.1949  1939.3818]]\n",
      "Camera 4 Optimized Camera Matrix:\n",
      " [[   0.45      0.4362   -0.7793  806.1666]\n",
      " [  -0.2658    0.8985    0.3495 -220.7843]\n",
      " [   0.8526    0.0499    0.5202  169.7508]]\n",
      "Camera 5 Optimized Camera Matrix:\n",
      " [[    0.3538    -0.4938     0.7944 -1873.4689]\n",
      " [    0.4325     0.8394     0.3292  -752.8458]\n",
      " [   -0.8294     0.2271     0.5105  1182.9457]]\n",
      "Camera 6 Optimized Camera Matrix:\n",
      " [[   0.8861   -0.1544   -0.437  -112.1726]\n",
      " [   0.0701    0.9767   -0.2029  255.2391]\n",
      " [   0.4582    0.1492    0.8762  141.9347]]\n"
     ]
    }
   ],
   "source": [
    "extrinsics = []\n",
    "extrinsics.append(np.hstack((np.eye((3)), np.zeros((3,1)))))\n",
    "\n",
    "for cam_idx in range(num_cameras):\n",
    "    r1, r2, r3, t1, t2, t3 = optimized_params[cam_idx]\n",
    "    rvec = np.array([r1,r2,r3], dtype=np.float64)\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    t = np.array([t1,t2,t3], dtype=np.float64).reshape((3,1))\n",
    "\n",
    "    optimized_camera_matrix = np.hstack((R,t))\n",
    "    extrinsics.append(optimized_camera_matrix)\n",
    "\n",
    "for cam_idx, cam_mat in enumerate(extrinsics):\n",
    "    print(f\"Camera {cam_idx+1} Optimized Camera Matrix:\\n\", cam_mat)\n",
    "\n",
    "np.savez('saved_cobotique/Extrinsics_optimized_16.npz', extrinsics[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative error on matrices multiplication (Total transfo = I ?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 calc: \n",
      " [[    0.3538    -0.4938     0.7944 -1873.4689]\n",
      " [    0.4325     0.8394     0.3292  -752.8458]\n",
      " [   -0.8294     0.2271     0.5105  1182.9457]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "T5: \n",
      " [[    0.3538    -0.4938     0.7944 -1873.4689]\n",
      " [    0.4325     0.8394     0.3292  -752.8458]\n",
      " [   -0.8294     0.2271     0.5105  1182.9457]\n",
      " [    0.         0.         0.         1.    ]]\n",
      "Cumulative error: \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "T = []\n",
    "\n",
    "for mat in extrinsics:\n",
    "    M = np.vstack((mat, np.array([0,0,0,1])))\n",
    "    T.append(M)\n",
    "\n",
    "T_next = []\n",
    "for i in range(len(T) - 1):\n",
    "    T_next.append(np.linalg.inv(T[i]) @ T[i+1])\n",
    "\n",
    "T5_calc = T_next[0] @ T_next[1] @ T_next[2] @ T_next[3]\n",
    "\n",
    "print('T5 calc: \\n', T5_calc)\n",
    "print('T5: \\n', T[4])\n",
    "\n",
    "I_calc = T5_calc @ np.linalg.inv(T[4])\n",
    "print('Cumulative error: \\n', np.abs(I_calc - np.eye(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D visualization of original and projected points onto images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circles(img, pts_2d_original, pts_2d_projected, text=True):\n",
    "    for p in range(len(pts_2d_original)):\n",
    "        x_orig, y_orig = map(int, pts_2d_original[p])  # Original 2D point\n",
    "        cv2.circle(img, (x_orig, y_orig), 8, (255, 0, 0), -1)\n",
    "\n",
    "        if pts_2d_projected is not None:\n",
    "            x_proj, y_proj = map(int, pts_2d_projected[p])  # Reprojected 3D point\n",
    "            cv2.circle(img, (x_proj, y_proj), 8, (0, 255, 0), -1)\n",
    "            cv2.line(img, (x_orig, y_orig), (x_proj, y_proj), (0, 255, 255), 2)\n",
    "\n",
    "        if text:\n",
    "            # Add labels\n",
    "            cv2.putText(img, str(p + 1), (x_orig + 10, y_orig), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.6, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(img, str(p + 1), (x_proj + 10, y_proj), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1-c2 nan\n",
      "c1-c3 nan\n",
      "c1-c4 4.761566\n",
      "c1-c5 14.065009\n",
      "c1-c6 0.17111018\n",
      "c2-c3 1.5695016\n",
      "c2-c4 nan\n",
      "c2-c5 2.9300756\n",
      "c2-c6 nan\n",
      "c3-c4 nan\n",
      "c3-c5 0.6328215\n",
      "c3-c6 nan\n",
      "c4-c5 nan\n",
      "c4-c6 21.653002\n",
      "c5-c6 nan\n"
     ]
    }
   ],
   "source": [
    "dir_images = r'C:\\Users\\LEA\\Desktop\\Poly\\Trampo\\data_cobotique\\calibration_0703\\corners_confirmed'\n",
    "\n",
    "projMat = extrinsics\n",
    "\n",
    "RMSE = []\n",
    "rmse_per_cam = {'c1-c2':[], 'c1-c3':[], 'c1-c4':[], 'c1-c5':[], 'c1-c6':[],\n",
    "                'c2-c3':[], 'c2-c4':[], 'c2-c5':[], 'c2-c6':[],\n",
    "                'c3-c4':[], 'c3-c5':[], 'c3-c6':[], 'c4-c5':[], 'c4-c6':[], 'c5-c6':[]}\n",
    "\n",
    "fig, axs = plt.subplots(6, 6, figsize=(20,14))\n",
    "axs = axs.flat\n",
    "k = 0\n",
    "\n",
    "for i in range(0, len(stereo_data['Camera']) - 1, 8):\n",
    "    j = i+1 # stereo image is the next one\n",
    "\n",
    "    pts1_im = stereo_data['Img_pts'][i].squeeze()\n",
    "    pts2_im = stereo_data['Img_pts'][j].squeeze()\n",
    "\n",
    "    c1 = int(stereo_data['Camera'][i]) - 1\n",
    "    c2 = int(stereo_data['Camera'][j]) - 1\n",
    "\n",
    "    t1 = float(stereo_data['Time'][i])\n",
    "    t2 = float(stereo_data['Time'][j])\n",
    "    assert abs(t1-t2) < time_threshold, f'Images are not matching: {t1:.4f} and {t2:.4f}'\n",
    "\n",
    "    undist_pts1 = cv2.undistortPoints(pts1_im, K[c1], D[c1]).reshape(-1, 2).T  # Shape (2, N)\n",
    "    undist_pts2 = cv2.undistortPoints(pts2_im, K[c2], D[c2]).reshape(-1, 2).T  # Shape (2, N)\n",
    "\n",
    "    # Perform triangulation\n",
    "    pts_4d = cv2.triangulatePoints(projMat[c1], projMat[c2], undist_pts1, undist_pts2)\n",
    "\n",
    "    # Convert from homogeneous coordinates\n",
    "    points_3d = pts_4d[:3, :] / pts_4d[3, :]  # Shape (3, N)\n",
    "    points_3d = points_3d.T  # Shape (N, 3)\n",
    "\n",
    "    img_path1 = os.path.join(dir_images, f'c{c1+1}', stereo_data['Name'][i])\n",
    "    img_path2 = os.path.join(dir_images, f'c{c2+1}', stereo_data['Name'][j])\n",
    "\n",
    "    # Visualize original and reprojected points (image 1)\n",
    "    img = cv2.imread(img_path1)\n",
    "\n",
    "    pts_2d_projected, _ = cv2.projectPoints(points_3d, projMat[c1][0:3,0:3], projMat[c1][0:3,3], K[c1], D[c1])\n",
    "    pts_2d_projected = pts_2d_projected.squeeze()\n",
    "    rmse1 = compute_rmse(pts1_im, points_3d, projMat[c1], K[c1], D[c1])\n",
    "\n",
    "    if i % 8 == 0:\n",
    "        img = draw_circles(img, pts1_im, pts_2d_projected)\n",
    "        axs[k].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[k].axis('off')\n",
    "        axs[k].set_title(f'{stereo_data['Name'][i]} RMSE = {rmse1:.2f}', fontsize=8)\n",
    "\n",
    "    # Visualize original and reprojected points (image 2)\n",
    "    img = cv2.imread(img_path2)\n",
    "    \n",
    "    pts_2d_projected, _ = cv2.projectPoints(points_3d, projMat[c2][0:3,0:3], projMat[c2][0:3,3], K[c2], D[c2])\n",
    "    pts_2d_projected = pts_2d_projected.squeeze()\n",
    "    rmse2 = compute_rmse(pts2_im, points_3d, projMat[c2], K[c2], D[c2])\n",
    "\n",
    "    if i % 8 == 0:\n",
    "        img = draw_circles(img, pts2_im, pts_2d_projected)\n",
    "        axs[k+1].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[k+1].axis('off')\n",
    "        axs[k+1].set_title(f'{stereo_data['Name'][j]} RMSE = {rmse2:.2f}', fontsize=8)\n",
    "        k += 2\n",
    "\n",
    "    rmse_per_cam[f'c{c1+1}-c{c2+1}'] += [rmse1, rmse2]\n",
    "\n",
    "fig.suptitle(\"Original 2D Points (Blue) vs. Projected 3D Points (Green)\")\n",
    "fig.tight_layout()\n",
    "plt.savefig('Figure_reprojection_23a.png')\n",
    "plt.show()\n",
    "\n",
    "for key, vals in rmse_per_cam.items():\n",
    "    print(key, np.mean(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D visualization of cameras in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(ax, T, label=\"Frame\", length=100.0):\n",
    "    \"\"\"Plots a 3D reference frame with arrows for X, Y, and Z axes.\"\"\"\n",
    "    origin = T[:3, 3]  # Extract translation (position)\n",
    "    R = T[:3, :3]      # Extract rotation matrix (orientation)\n",
    "\n",
    "    # Define the x, y, z unit vectors from the rotation matrix\n",
    "    x_axis = R[:, 0] * length  # X-direction\n",
    "    y_axis = R[:, 1] * length  # Y-direction\n",
    "    z_axis = R[:, 2] * length  # Z-direction\n",
    "\n",
    "    # Plot arrows for the axes\n",
    "    ax.quiver(*origin, *x_axis, color='r', arrow_length_ratio=0.3)  # X-axis (Red)\n",
    "    ax.quiver(*origin, *y_axis, color='g', arrow_length_ratio=0.3)  # Y-axis (Green)\n",
    "    ax.quiver(*origin, *z_axis, color='b', arrow_length_ratio=0.3)  # Z-axis (Blue)\n",
    "\n",
    "    # Label the frame\n",
    "    ax.text(*origin, label, fontsize=12, color='black')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frames\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i, T in enumerate(extrinsics):\n",
    "    T = np.vstack((T, np.array([0,0,0,1])))\n",
    "    plot_frame(ax, T, label=f'Camera {i+1}')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.title(\"3D Reference Frames\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation of reference points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "[[ 438.9573  612.0837 1547.7601]\n",
      " [ 597.9066  711.9742 1308.5292]\n",
      " [ 699.2227  561.614  1688.9116]]\n",
      "5.492077\n",
      "5.1638227\n",
      "0 2\n",
      "[[ 438.793   613.6914 1567.5546]\n",
      " [ 594.5112  718.7676 1320.204 ]\n",
      " [ 694.4538  558.0953 1703.2388]]\n",
      "3.368347\n",
      "2.668509\n",
      "0 3\n",
      "[[ 438.4645  564.0198 1502.3374]\n",
      " [ 584.0068  668.7175 1283.5745]\n",
      " [ 683.8554  496.4674 1629.6431]]\n",
      "14.8665695\n",
      "13.897979\n",
      "0 4\n",
      "[[ 443.907   621.881  1555.2384]\n",
      " [ 600.2332  726.2197 1307.9934]\n",
      " [ 708.6593  574.9991 1718.9465]]\n",
      "8.828814\n",
      "7.624548\n",
      "0 5\n",
      "[[ 468.4442  659.6081 1675.1582]\n",
      " [ 619.8766  750.5546 1393.7847]\n",
      " [ 751.7582  609.4136 1855.8385]]\n",
      "1.7495277\n",
      "1.6301049\n",
      "1 2\n",
      "[[ 484.8057  562.0983 1552.0518]\n",
      " [ 635.1198  683.4676 1305.4451]\n",
      " [ 742.7792  505.2459 1682.3501]]\n",
      "0.9822641\n",
      "0.8384604\n",
      "1 3\n",
      "[[ 484.5439  564.8813 1546.3999]\n",
      " [ 635.4725  679.1663 1308.2439]\n",
      " [ 756.7451  488.5258 1682.8137]]\n",
      "1.4410608\n",
      "1.6889228\n",
      "1 4\n",
      "[[ 433.8782  632.5175 1549.067 ]\n",
      " [ 597.9603  748.4139 1293.452 ]\n",
      " [ 729.8957  549.9414 1690.686 ]]\n",
      "4.4517183\n",
      "4.741482\n",
      "1 5\n",
      "[[ 441.6821  600.3126 1551.7719]\n",
      " [ 604.2448  705.1942 1309.2639]\n",
      " [ 701.4706  545.7132 1693.789 ]]\n",
      "6.575921\n",
      "5.8115573\n",
      "2 3\n",
      "[[ 488.306   565.5505 1548.4202]\n",
      " [ 636.9043  681.1872 1308.6283]\n",
      " [ 753.472   488.2463 1676.3356]]\n",
      "1.4152157\n",
      "1.8426162\n",
      "2 4\n",
      "[[ 292.4399  748.6663 1606.1691]\n",
      " [ 493.8877  850.5027 1320.7715]\n",
      " [ 415.5226  852.6902 1849.5286]]\n",
      "3.7342212\n",
      "3.8886416\n",
      "2 5\n",
      "[[ 439.6528  604.6122 1569.8562]\n",
      " [ 600.8577  711.8724 1319.7516]\n",
      " [ 694.2444  545.991  1707.3865]]\n",
      "2.9214325\n",
      "3.299426\n",
      "3 4\n",
      "[[ 502.0834  580.6138 1543.2786]\n",
      " [ 655.2588  695.1725 1303.2966]\n",
      " [ 783.5812  508.5767 1690.0598]]\n",
      "6.302303\n",
      "5.4948273\n",
      "3 5\n",
      "[[ 416.8096  534.3994 1475.66  ]\n",
      " [ 573.7291  650.9434 1272.1876]\n",
      " [ 646.0089  458.1698 1587.5757]]\n",
      "8.702172\n",
      "7.305401\n",
      "4 5\n",
      "[[ 446.2861  614.1705 1557.4976]\n",
      " [ 609.9009  720.8671 1307.423 ]\n",
      " [ 708.424   566.3973 1722.7377]]\n",
      "8.559375\n",
      "8.912866\n"
     ]
    }
   ],
   "source": [
    "# Load points from JSON file\n",
    "with open(\"saved_cobotique/clicked_points_adjusted.json\", \"r\") as file:\n",
    "    image_points = json.load(file)\n",
    "\n",
    "fig, axs = plt.subplots(5, 6, figsize=(16,12))\n",
    "axs = axs.flatten()\n",
    "k = 0\n",
    "\n",
    "projMat = extrinsics\n",
    "\n",
    "ref_points = []\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    c1 = int(cams[i][-1]) - 1\n",
    "\n",
    "    for j in range(i+1,6):\n",
    "        c2 = int(cams[j][-1]) - 1\n",
    "        print(c1, c2)\n",
    "        \n",
    "        pts1_im = np.array(image_points[cams[i]], dtype=np.float32)\n",
    "        pts2_im = np.array(image_points[cams[j]], dtype=np.float32)\n",
    "\n",
    "        img_path1 = img_paths[i]\n",
    "        img_path2 = img_paths[j]\n",
    "\n",
    "        undist_pts1 = cv2.undistortPoints(pts1_im, K[c1], D[c1]).reshape(-1, 2).T  # Shape (2, N)\n",
    "        undist_pts2 = cv2.undistortPoints(pts2_im, K[c2], D[c2]).reshape(-1, 2).T  # Shape (2, N)\n",
    "\n",
    "        # Perform triangulation\n",
    "        pts_4d = cv2.triangulatePoints(projMat[c1], projMat[c2], undist_pts1, undist_pts2)\n",
    "\n",
    "        # Convert from homogeneous coordinates\n",
    "        points_3d = pts_4d[:3, :] / pts_4d[3, :]  # Shape (3, N)\n",
    "        points_3d = points_3d.T  # Shape (N, 3)\n",
    "        print(points_3d)\n",
    "\n",
    "        # Visualize original and reprojected points (image 1)\n",
    "        img = cv2.imread(img_path1)\n",
    "\n",
    "        pts_2d_projected, _ = cv2.projectPoints(points_3d, projMat[c1][0:3,0:3], projMat[c1][0:3,3], K[c1], D[c1])\n",
    "        pts_2d_projected = pts_2d_projected.squeeze()\n",
    "        rmse1 = compute_rmse(pts1_im, points_3d, projMat[c1], K[c1], D[c1])\n",
    "\n",
    "        print(rmse1)\n",
    "\n",
    "        img = draw_circles(img, pts1_im, pts_2d_projected)\n",
    "        axs[k].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[k].axis('off')\n",
    "        axs[k].set_title(f'{stereo_data['Name'][i]} RMSE = {rmse1:.2f}', fontsize=8)\n",
    "\n",
    "        # Visualize original and reprojected points (image 2)\n",
    "        img = cv2.imread(img_path2)\n",
    "        \n",
    "        pts_2d_projected, _ = cv2.projectPoints(points_3d, projMat[c2][0:3,0:3], projMat[c2][0:3,3], K[c2], D[c2])\n",
    "        pts_2d_projected = pts_2d_projected.squeeze()\n",
    "        rmse2 = compute_rmse(pts2_im, points_3d, projMat[c2], K[c2], D[c2])\n",
    "\n",
    "        print(rmse2)\n",
    "\n",
    "        if rmse1 < 1 and rmse2 < 1:\n",
    "            ref_points.append(points_3d)\n",
    "\n",
    "        img = draw_circles(img, pts2_im, pts_2d_projected)\n",
    "        axs[k+1].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[k+1].axis('off')\n",
    "        axs[k+1].set_title(f'{stereo_data['Name'][j]} RMSE = {rmse2:.2f}', fontsize=8)\n",
    "\n",
    "        k += 2\n",
    "\n",
    "fig.suptitle(\"Original 2D Points (Blue) vs. Projected 3D Points (Green)\")\n",
    "fig.tight_layout()\n",
    "plt.savefig('Figure_reprojection_20b.png')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D reference points on tabletop as global reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 491.8386  686.3479 1740.49  ]\n",
      " [ 666.5218  804.0645 1488.0469]\n",
      " [ 777.1145  626.6667 1908.1335]]\n",
      "[[    0.8824     0.0817     0.4633 -1296.4921]\n",
      " [   -0.1719     0.9727     0.1558  -854.2322]\n",
      " [   -0.4379    -0.2171     0.8724 -1153.9842]\n",
      " [    0.         0.         0.         1.    ]]\n"
     ]
    }
   ],
   "source": [
    "ref_points = np.array(ref_points)\n",
    "ref_points_mean = np.mean(ref_points, axis=0)\n",
    "print(ref_points_mean)\n",
    "\n",
    "t = ref_points_mean[0].reshape((3,1))\n",
    "x = ref_points_mean[1] - ref_points_mean[0] / np.linalg.norm(ref_points_mean[1] - ref_points_mean[0])\n",
    "y = ref_points_mean[2] - ref_points_mean[0] / np.linalg.norm(ref_points_mean[2] - ref_points_mean[0])\n",
    "\n",
    "z = np.cross(x, y)\n",
    "\n",
    "x = x.reshape((3,1))\n",
    "y = y.reshape((3,1))\n",
    "z = z.reshape((3,1))\n",
    "\n",
    "R_table = np.hstack((x,y,z))\n",
    "T_table = np.vstack((np.hstack((R, t)), np.array([0,0,0,1])))\n",
    "\n",
    "tt_T_world = np.linalg.inv(T_table)\n",
    "print(tt_T_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frames\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i, T in enumerate(extrinsics):\n",
    "    T = np.vstack((T, np.array([0,0,0,1])))\n",
    "    T = tt_T_world @ T\n",
    "    plot_frame(ax, T, label=f'Camera {i+1}')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.title(\"3D Reference Frames\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trampo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
